{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1xnOCF5EBjDDapoE7LJOccB0nM1yz4Ir5",
      "authorship_tag": "ABX9TyNg6HZf6u4yZf52ZR6i4Wvx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caaszj/GLAFormer/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import math\n",
        "import os\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "from collections import Counter\n",
        "\n",
        "# ===== 数据预处理和加载 =====\n",
        "class HSIChangeDetectionDataset(Dataset):\n",
        "    def __init__(self, before_path, after_path, gt_path, patch_size=9, mode='train',\n",
        "                 augment=False, mixup_prob=0.5, mixup_alpha=0.2):\n",
        "        self.before = self.load_mat(before_path)  # (H, W, C)\n",
        "        self.after = self.load_mat(after_path)\n",
        "        self.gt = self.load_gt(gt_path)  # (H, W)\n",
        "\n",
        "        # 检查标签值\n",
        "        unique_labels = np.unique(self.gt)\n",
        "        print(f\"标签中的唯一值: {unique_labels}\")\n",
        "\n",
        "        # 特征归一化\n",
        "        self.before = self._normalize(self.before)\n",
        "        self.after = self._normalize(self.after)\n",
        "\n",
        "        # 数据增强设置\n",
        "        self.augment = augment and mode == 'train'\n",
        "        self.mixup_prob = mixup_prob\n",
        "        self.mixup_alpha = mixup_alpha\n",
        "\n",
        "        self.patch_size = patch_size\n",
        "        self.half = patch_size // 2\n",
        "        self.mode = mode\n",
        "\n",
        "        # 生成有效位置索引\n",
        "        self.coords = self.get_valid_coords()\n",
        "\n",
        "        # 计算类别分布\n",
        "        self.class_counts = self._get_class_distribution()\n",
        "        print(f\"类别分布 - 未变化: {self.class_counts[0]}, 变化: {self.class_counts[1]}\")\n",
        "\n",
        "        # 划分训练/验证/测试集，使用分层抽样保持类别分布\n",
        "        np.random.seed(42)  # 设置随机种子以确保可重复性\n",
        "\n",
        "        # 分离变化和未变化样本索引\n",
        "        change_indices = [i for i, (r, c) in enumerate(self.coords) if self.gt[r, c] == 255]\n",
        "        no_change_indices = [i for i, (r, c) in enumerate(self.coords) if self.gt[r, c] == 0]\n",
        "\n",
        "        # 随机打乱两类索引\n",
        "        np.random.shuffle(change_indices)\n",
        "        np.random.shuffle(no_change_indices)\n",
        "\n",
        "        # 划分比例\n",
        "        train_ratio, val_ratio = 0.7, 0.15\n",
        "\n",
        "        # 计算各集合的样本数量\n",
        "        train_change_num = int(len(change_indices) * train_ratio)\n",
        "        val_change_num = int(len(change_indices) * val_ratio)\n",
        "\n",
        "        train_no_change_num = int(len(no_change_indices) * train_ratio)\n",
        "        val_no_change_num = int(len(no_change_indices) * val_ratio)\n",
        "\n",
        "        # 划分样本\n",
        "        if mode == 'train':\n",
        "            change_idx = change_indices[:train_change_num]\n",
        "            no_change_idx = no_change_indices[:train_no_change_num]\n",
        "            self.selected_indices = change_idx + no_change_idx\n",
        "        elif mode == 'val':\n",
        "            change_idx = change_indices[train_change_num:train_change_num+val_change_num]\n",
        "            no_change_idx = no_change_indices[train_no_change_num:train_no_change_num+val_no_change_num]\n",
        "            self.selected_indices = change_idx + no_change_idx\n",
        "        else:  # test\n",
        "            change_idx = change_indices[train_change_num+val_change_num:]\n",
        "            no_change_idx = no_change_indices[train_no_change_num+val_no_change_num:]\n",
        "            self.selected_indices = change_idx + no_change_idx\n",
        "\n",
        "        # 计算当前集合的类别分布\n",
        "        self.subset_class_counts = self._get_subset_distribution()\n",
        "        print(f\"{mode} 集合 - 未变化: {self.subset_class_counts[0]}, 变化: {self.subset_class_counts[1]}\")\n",
        "\n",
        "    def _normalize(self, data):\n",
        "        \"\"\"逐波段归一化，更稳定\"\"\"\n",
        "        normalized_data = np.zeros_like(data, dtype=np.float32)\n",
        "        for i in range(data.shape[2]):  # 遍历每个波段\n",
        "            band = data[:,:,i]\n",
        "            band_min, band_max = band.min(), band.max()\n",
        "            if band_max > band_min:\n",
        "                normalized_data[:,:,i] = (band - band_min) / (band_max - band_min)\n",
        "        return normalized_data\n",
        "\n",
        "    def _get_class_distribution(self):\n",
        "        \"\"\"计算变化/非变化类别的样本数量\"\"\"\n",
        "        class_counts = [0, 0]\n",
        "        for i, j in self.coords:\n",
        "            label = 1 if self.gt[i, j] == 255 else 0\n",
        "            class_counts[label] += 1\n",
        "        return class_counts\n",
        "\n",
        "    def _get_subset_distribution(self):\n",
        "        \"\"\"计算当前子集的类别分布\"\"\"\n",
        "        class_counts = [0, 0]\n",
        "        for idx in self.selected_indices:\n",
        "            i, j = self.coords[idx]\n",
        "            label = 1 if self.gt[i, j] == 255 else 0\n",
        "            class_counts[label] += 1\n",
        "        return class_counts\n",
        "\n",
        "    def load_mat(self, path):\n",
        "        mat = loadmat(path)\n",
        "        # 获取.mat文件中的第一个键，假设它是数据键\n",
        "        keys = [k for k in mat.keys() if not k.startswith('__')]\n",
        "        if 'river_before' in mat:\n",
        "            return mat['river_before'].astype(np.float32)\n",
        "        elif 'river_after' in mat:\n",
        "            return mat['river_after'].astype(np.float32)\n",
        "        elif len(keys) > 0:\n",
        "            return mat[keys[0]].astype(np.float32)\n",
        "        else:\n",
        "            raise ValueError(f\"无法从{path}加载数据\")\n",
        "\n",
        "    def load_gt(self, path):\n",
        "        mat = loadmat(path)\n",
        "        keys = [k for k in mat.keys() if not k.startswith('__')]\n",
        "        if 'lakelabel_v1' in mat:\n",
        "            return mat['lakelabel_v1'].astype(np.int64)\n",
        "        elif len(keys) > 0:\n",
        "            return mat[keys[0]].astype(np.int64)\n",
        "        else:\n",
        "            raise ValueError(f\"无法从{path}加载标签\")\n",
        "\n",
        "    def get_valid_coords(self):\n",
        "        H, W = self.gt.shape\n",
        "        coords = []\n",
        "        for i in range(self.half, H-self.half):\n",
        "            for j in range(self.half, W-self.half):\n",
        "                if self.gt[i, j] == 0 or self.gt[i, j] == 255:  # 只处理有效像素\n",
        "                    coords.append((i, j))\n",
        "        return np.array(coords)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.selected_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"获取数据样本\n",
        "        Returns:\n",
        "            before_patch: 第一时相patch\n",
        "            after_patch: 第二时相patch\n",
        "            label: 标签\n",
        "            mixup_params: 包含mixup参数的字典，如果没有使用mixup则为None\n",
        "        \"\"\"\n",
        "        coord_idx = self.selected_indices[idx]\n",
        "        i, j = self.coords[coord_idx]\n",
        "\n",
        "        # 提取双时相patch\n",
        "        before_patch = self.before[i-self.half:i+self.half+1, j-self.half:j+self.half+1, :].copy()\n",
        "        after_patch = self.after[i-self.half:i+self.half+1, j-self.half:j+self.half+1, :].copy()\n",
        "\n",
        "        # 数据增强\n",
        "        if self.augment and np.random.random() < 0.5:\n",
        "            before_patch, after_patch = self._augment_patches(before_patch, after_patch)\n",
        "\n",
        "        # 转为CHW格式\n",
        "        before_patch = torch.from_numpy(before_patch.copy()).permute(2,0,1).float()\n",
        "        after_patch = torch.from_numpy(after_patch.copy()).permute(2,0,1).float()\n",
        "        label = 1 if self.gt[i, j] == 255 else 0  # 确保标签为0或1\n",
        "\n",
        "        # MixUp增强 (仅在训练时)\n",
        "        mixup_params = None\n",
        "        if self.augment and np.random.random() < self.mixup_prob:\n",
        "            # 随机选择另一个样本\n",
        "            other_idx = np.random.randint(0, len(self.selected_indices))\n",
        "            other_coord_idx = self.selected_indices[other_idx]\n",
        "            other_i, other_j = self.coords[other_coord_idx]\n",
        "\n",
        "            other_before = self.before[other_i-self.half:other_i+self.half+1, other_j-self.half:other_j+self.half+1, :].copy()\n",
        "            other_after = self.after[other_i-self.half:other_i+self.half+1, other_j-self.half:other_j+self.half+1, :].copy()\n",
        "\n",
        "            other_before = torch.from_numpy(other_before.copy()).permute(2,0,1).float()\n",
        "            other_after = torch.from_numpy(other_after.copy()).permute(2,0,1).float()\n",
        "            other_label = 1 if self.gt[other_i, other_j] == 255 else 0\n",
        "\n",
        "            # 生成混合系数\n",
        "            lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
        "\n",
        "            # 混合样本\n",
        "            before_patch = lam * before_patch + (1 - lam) * other_before\n",
        "            after_patch = lam * after_patch + (1 - lam) * other_after\n",
        "\n",
        "            # 保存mixup参数\n",
        "            mixup_params = {\n",
        "                'lam': lam,\n",
        "                'other_label': other_label\n",
        "            }\n",
        "\n",
        "        return before_patch, after_patch, label, mixup_params\n",
        "\n",
        "    def _augment_patches(self, before_patch, after_patch):\n",
        "        \"\"\"数据增强：随机旋转和翻转\"\"\"\n",
        "        k = np.random.randint(0, 4)  # 0-3的随机数，表示旋转次数\n",
        "\n",
        "        # 随机旋转\n",
        "        before_patch = np.rot90(before_patch, k=k, axes=(0, 1))\n",
        "        after_patch = np.rot90(after_patch, k=k, axes=(0, 1))\n",
        "\n",
        "        # 随机翻转\n",
        "        if np.random.random() < 0.5:\n",
        "            before_patch = np.flip(before_patch, axis=0)\n",
        "            after_patch = np.flip(after_patch, axis=0)\n",
        "\n",
        "        if np.random.random() < 0.5:\n",
        "            before_patch = np.flip(before_patch, axis=1)\n",
        "            after_patch = np.flip(after_patch, axis=1)\n",
        "\n",
        "        return before_patch, after_patch\n",
        "\n",
        "# ===== 损失函数 =====\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha  # 权重因子\n",
        "        self.gamma = gamma  # 聚焦因子\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
        "        pt = torch.exp(-ce_loss)  # 预测的概率\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "# MixUp损失处理\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "# ===== 注意力模块 =====\n",
        "class GLAM(nn.Module):\n",
        "    \"\"\"改进的全局-局部注意力模块，支持多尺度特征融合\"\"\"\n",
        "    def __init__(self, dim, num_heads=8, window_size=3, attn_drop=0.1):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.attn_drop = attn_drop\n",
        "\n",
        "        # 确保维度可以被头数整除\n",
        "        self.split_dim = dim // 2\n",
        "        self.num_heads_local = max(1, num_heads // 2)  # 至少1个头\n",
        "        # 确保head_dim_local是整数\n",
        "        self.head_dim_local = self.split_dim // self.num_heads_local\n",
        "        self.split_dim = self.head_dim_local * self.num_heads_local  # 重新计算以确保可整除\n",
        "\n",
        "        self.window_size = window_size\n",
        "\n",
        "        # Local分支\n",
        "        self.local_qkv = nn.Conv2d(self.split_dim, self.split_dim*3, kernel_size=1)\n",
        "        self.local_dropout = nn.Dropout(attn_drop)\n",
        "\n",
        "        # Global分支 - 多尺度特征融合\n",
        "        self.global_q = nn.Conv2d(self.split_dim, self.split_dim, kernel_size=1)\n",
        "        self.global_kv1 = nn.Conv2d(self.split_dim, self.split_dim*2, kernel_size=1)  # 原始尺度\n",
        "        self.global_kv2 = nn.Conv2d(self.split_dim, self.split_dim*2, kernel_size=1)  # 下采样2倍\n",
        "        self.global_kv3 = nn.Conv2d(self.split_dim, self.split_dim*2, kernel_size=1)  # 下采样4倍\n",
        "        self.global_dropout = nn.Dropout(attn_drop)\n",
        "\n",
        "        # 融合不同尺度的注意力结果\n",
        "        self.scale_fusion = nn.Conv2d(self.split_dim*3, self.split_dim, kernel_size=1)\n",
        "\n",
        "        # 确保投影层维度正确\n",
        "        self.proj = nn.Conv2d(self.split_dim*2, dim, kernel_size=1)\n",
        "        self.proj_drop = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        # 分割通道维度\n",
        "        x_split = torch.split(x, [self.split_dim, C - self.split_dim], dim=1)\n",
        "        x_local = x_split[0]\n",
        "        x_global = x_split[0] if len(x_split) == 1 else x_split[1]\n",
        "\n",
        "        # 保证x_global的维度与split_dim一致\n",
        "        if x_global.shape[1] != self.split_dim:\n",
        "            x_global = F.adaptive_avg_pool2d(x_global, (H, W))\n",
        "            x_global = F.interpolate(x_global, size=(H, W), mode='bilinear', align_corners=False)\n",
        "            if x_global.shape[1] > self.split_dim:\n",
        "                x_global = x_global[:, :self.split_dim, :, :]\n",
        "            elif x_global.shape[1] < self.split_dim:\n",
        "                padding = self.split_dim - x_global.shape[1]\n",
        "                x_global = torch.cat([x_global, torch.zeros(B, padding, H, W, device=x.device)], dim=1)\n",
        "\n",
        "        # Local Attention\n",
        "        qkv = self.local_qkv(x_local)  # [B, 3*split_dim, H, W]\n",
        "        qkv = qkv.reshape(B, 3, self.num_heads_local, self.head_dim_local, H, W)\n",
        "        q, k, v = qkv[:, 0], qkv[:, 1], qkv[:, 2]  # [B, num_heads_local, head_dim_local, H, W]\n",
        "\n",
        "        # 重塑张量以计算注意力\n",
        "        q = q.reshape(B, self.num_heads_local, self.head_dim_local, H*W)\n",
        "        k = k.reshape(B, self.num_heads_local, self.head_dim_local, H*W)\n",
        "        v = v.reshape(B, self.num_heads_local, self.head_dim_local, H*W)\n",
        "\n",
        "        # 计算注意力分数 - 修正维度顺序\n",
        "        attn = torch.matmul(q.transpose(-2, -1), k) / math.sqrt(self.head_dim_local)  # [B, num_heads_local, H*W, H*W]\n",
        "        attn = F.softmax(attn, dim=-1)\n",
        "        attn = self.local_dropout(attn)\n",
        "\n",
        "        # 应用注意力\n",
        "        local_out = torch.matmul(v, attn.transpose(-2, -1))  # [B, num_heads_local, head_dim_local, H*W]\n",
        "        local_out = local_out.reshape(B, self.split_dim, H, W)\n",
        "\n",
        "        # Global Attention - 多尺度特征\n",
        "        q_g = self.global_q(x_global)  # [B, split_dim, H, W]\n",
        "\n",
        "        # 原始尺度\n",
        "        kv1 = self.global_kv1(x_global)  # [B, 2*split_dim, H, W]\n",
        "\n",
        "        # 下采样2倍\n",
        "        x_pool2 = F.avg_pool2d(x_global, 2, stride=2)\n",
        "        kv2 = self.global_kv2(x_pool2)  # [B, 2*split_dim, H/2, W/2]\n",
        "\n",
        "        # 下采样4倍\n",
        "        x_pool4 = F.avg_pool2d(x_global, 4, stride=4)\n",
        "        kv3 = self.global_kv3(x_pool4)  # [B, 2*split_dim, H/4, W/4]\n",
        "\n",
        "        # 处理不同尺度\n",
        "        global_out1 = self._process_scale(q_g, kv1, H, W, \"scale1\")\n",
        "        global_out2 = self._process_scale(q_g, kv2, H//2, W//2, \"scale2\")\n",
        "        global_out3 = self._process_scale(q_g, kv3, H//4, W//4, \"scale3\")\n",
        "\n",
        "        # 融合不同尺度的结果\n",
        "        multi_scale_out = torch.cat([global_out1, global_out2, global_out3], dim=1)\n",
        "        global_out = self.scale_fusion(multi_scale_out)  # [B, split_dim, H, W]\n",
        "\n",
        "        # 连接并投影\n",
        "        out = torch.cat([local_out, global_out], dim=1)\n",
        "        out = self.proj(out)\n",
        "        out = self.proj_drop(out)\n",
        "        return out\n",
        "\n",
        "    def _process_scale(self, q, kv, h, w, scale_name):\n",
        "        B = q.shape[0]\n",
        "\n",
        "        # 分离kv\n",
        "        kv = kv.reshape(B, 2, self.num_heads_local, self.head_dim_local, h, w)\n",
        "        k, v = kv[:, 0], kv[:, 1]  # [B, num_heads_local, head_dim_local, h, w]\n",
        "\n",
        "        # 重塑查询\n",
        "        q_g = q.reshape(B, self.num_heads_local, self.head_dim_local, q.shape[2], q.shape[3])\n",
        "        q_g = q_g.reshape(B, self.num_heads_local, self.head_dim_local, -1)  # [B, num_heads_local, head_dim_local, H*W]\n",
        "\n",
        "        # 重塑键值\n",
        "        k_g = k.reshape(B, self.num_heads_local, self.head_dim_local, -1)  # [B, num_heads_local, head_dim_local, h*w]\n",
        "        v_g = v.reshape(B, self.num_heads_local, self.head_dim_local, -1)  # [B, num_heads_local, head_dim_local, h*w]\n",
        "\n",
        "        # 计算注意力分数\n",
        "        attn_g = torch.matmul(q_g.transpose(-2, -1), k_g) / math.sqrt(self.head_dim_local)  # [B, num_heads_local, H*W, h*w]\n",
        "        attn_g = F.softmax(attn_g, dim=-1)\n",
        "        attn_g = self.global_dropout(attn_g)\n",
        "\n",
        "        # 应用注意力\n",
        "        out = torch.matmul(v_g, attn_g.transpose(-2, -1))  # [B, num_heads_local, head_dim_local, H*W]\n",
        "        out = out.reshape(B, self.split_dim, q.shape[2], q.shape[3])  # [B, split_dim, H, W]\n",
        "\n",
        "        return out\n",
        "\n",
        "# 跨时相注意力模块\n",
        "class CrossTemporalAttention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, attn_drop=0.1):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        # 双向变换投影\n",
        "        self.t1_to_t2_proj = nn.Linear(dim, dim)\n",
        "        self.t2_to_t1_proj = nn.Linear(dim, dim)\n",
        "\n",
        "        # QKV投影\n",
        "        self.q_proj = nn.Linear(dim, dim)\n",
        "        self.k_proj = nn.Linear(dim, dim)\n",
        "        self.v_proj = nn.Linear(dim, dim)\n",
        "\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.out_proj = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        \"\"\"\n",
        "        输入:\n",
        "            x1: 第一时相特征 [B, C, H, W]\n",
        "            x2: 第二时相特征 [B, C, H, W]\n",
        "        \"\"\"\n",
        "        B, C, H, W = x1.shape\n",
        "\n",
        "        # 重塑为序列形式\n",
        "        x1_flat = x1.flatten(2).transpose(1, 2)  # [B, H*W, C]\n",
        "        x2_flat = x2.flatten(2).transpose(1, 2)  # [B, H*W, C]\n",
        "\n",
        "        # 计算从t1到t2的注意力\n",
        "        t1_to_t2 = self._compute_cross_attention(\n",
        "            self.t1_to_t2_proj(x1_flat),  # 查询\n",
        "            x2_flat,  # 键\n",
        "            x2_flat   # 值\n",
        "        )\n",
        "\n",
        "        # 计算从t2到t1的注意力\n",
        "        t2_to_t1 = self._compute_cross_attention(\n",
        "            self.t2_to_t1_proj(x2_flat),  # 查询\n",
        "            x1_flat,  # 键\n",
        "            x1_flat   # 值\n",
        "        )\n",
        "\n",
        "        # 重塑回空间形式\n",
        "        t1_to_t2 = t1_to_t2.transpose(1, 2).reshape(B, C, H, W)\n",
        "        t2_to_t1 = t2_to_t1.transpose(1, 2).reshape(B, C, H, W)\n",
        "\n",
        "        # 返回增强后的双时相特征\n",
        "        return t1_to_t2, t2_to_t1\n",
        "\n",
        "    def _compute_cross_attention(self, q_input, k_input, v_input):\n",
        "        B, L, C = q_input.shape\n",
        "\n",
        "        # 投影QKV\n",
        "        q = self.q_proj(q_input).reshape(B, L, self.num_heads, self.head_dim).permute(0, 2, 1, 3)  # [B, num_heads, L, head_dim]\n",
        "        k = self.k_proj(k_input).reshape(B, L, self.num_heads, self.head_dim).permute(0, 2, 1, 3)  # [B, num_heads, L, head_dim]\n",
        "        v = self.v_proj(v_input).reshape(B, L, self.num_heads, self.head_dim).permute(0, 2, 1, 3)  # [B, num_heads, L, head_dim]\n",
        "\n",
        "        # 计算注意力分数\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale  # [B, num_heads, L, L]\n",
        "        attn = F.softmax(attn, dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        # 应用注意力\n",
        "        out = (attn @ v).transpose(1, 2).reshape(B, L, C)  # [B, L, C]\n",
        "        out = self.out_proj(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# 改进的通道门控融合网络\n",
        "class CGFN(nn.Module):\n",
        "    def __init__(self, dim, expansion=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        hidden_dim = dim * expansion\n",
        "\n",
        "        # 增加Squeeze-and-Excitation模块\n",
        "        self.se = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(dim, dim // 16, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(dim // 16, dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # 增加1x1卷积降维\n",
        "        self.conv1 = nn.Conv2d(dim, hidden_dim, 1)\n",
        "\n",
        "        # 多分支深度可分离卷积\n",
        "        self.dwconv3 = nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1, groups=hidden_dim)\n",
        "        self.dwconv5 = nn.Conv2d(hidden_dim, hidden_dim, 5, padding=2, groups=hidden_dim)\n",
        "        self.dwconv7 = nn.Conv2d(hidden_dim, hidden_dim, 7, padding=3, groups=hidden_dim)\n",
        "\n",
        "        # 批归一化\n",
        "        self.norm3 = nn.BatchNorm2d(hidden_dim)\n",
        "        self.norm5 = nn.BatchNorm2d(hidden_dim)\n",
        "        self.norm7 = nn.BatchNorm2d(hidden_dim)\n",
        "\n",
        "        # 门控机制改进\n",
        "        self.gate1 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.gate2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.gate3 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # 添加跳跃连接\n",
        "        self.skip_conn = nn.Conv2d(dim, dim, 1)\n",
        "\n",
        "        # 最终投影层\n",
        "        self.conv2 = nn.Conv2d(hidden_dim*3, dim, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.final_norm = nn.BatchNorm2d(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Squeeze-and-Excitation注意力\n",
        "        se_weight = self.se(x)\n",
        "        x = x * se_weight\n",
        "\n",
        "        # 保存残差连接\n",
        "        residual = self.skip_conn(x)\n",
        "\n",
        "        # 1x1卷积升维\n",
        "        x = self.conv1(x)\n",
        "\n",
        "        # 多分支深度可分离卷积\n",
        "        x1 = self.dwconv3(x)\n",
        "        x1 = self.norm3(x1)\n",
        "        x2 = self.dwconv5(x)\n",
        "        x2 = self.norm5(x2)\n",
        "        x3 = self.dwconv7(x)\n",
        "        x3 = self.norm7(x3)\n",
        "\n",
        "        # 应用门控机制\n",
        "        g1 = self.gate1(x1)\n",
        "        g2 = self.gate2(x2)\n",
        "        g3 = self.gate3(x3)\n",
        "\n",
        "        # 门控融合\n",
        "        x1 = x1 * g1\n",
        "        x2 = x2 * g2\n",
        "        x3 = x3 * g3\n",
        "\n",
        "        # 特征融合\n",
        "        x = torch.cat([x1, x2, x3], dim=1)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.final_norm(x)\n",
        "\n",
        "        # 添加残差连接\n",
        "        return x + residual\n",
        "\n",
        "# 多尺度金字塔融合模块\n",
        "class MultiScalePyramidFusion(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # 多尺度特征提取\n",
        "        self.scale1_conv = nn.Conv2d(dim, dim//4, kernel_size=3, padding=1)\n",
        "        self.scale2_conv = nn.Conv2d(dim, dim//4, kernel_size=3, padding=1)\n",
        "        self.scale3_conv = nn.Conv2d(dim, dim//4, kernel_size=3, padding=1)\n",
        "        self.scale4_conv = nn.Conv2d(dim, dim//4, kernel_size=3, padding=1)\n",
        "\n",
        "        # 注意力融合\n",
        "        self.attn_fusion = nn.Sequential(\n",
        "            nn.Conv2d(dim, dim, kernel_size=1),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # 最终融合\n",
        "        self.fusion_conv = nn.Conv2d(dim, dim, kernel_size=1)\n",
        "        self.norm = nn.BatchNorm2d(dim)\n",
        "        self.act = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 多尺度下采样\n",
        "        x_scale1 = self.scale1_conv(x)  # 原始尺度\n",
        "\n",
        "        # 下采样到1/2\n",
        "        x_down2 = F.avg_pool2d(x, kernel_size=2, stride=2)\n",
        "        x_scale2 = self.scale2_conv(x_down2)\n",
        "        x_scale2 = F.interpolate(x_scale2, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        # 下采样到1/4\n",
        "        x_down4 = F.avg_pool2d(x, kernel_size=4, stride=4)\n",
        "        x_scale3 = self.scale3_conv(x_down4)\n",
        "        x_scale3 = F.interpolate(x_scale3, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        # 下采样到1/8\n",
        "        x_down8 = F.avg_pool2d(x, kernel_size=8, stride=8)\n",
        "        x_scale4 = self.scale4_conv(x_down8)\n",
        "        x_scale4 = F.interpolate(x_scale4, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        # 特征拼接\n",
        "        multi_scale_feat = torch.cat([x_scale1, x_scale2, x_scale3, x_scale4], dim=1)\n",
        "\n",
        "        # 注意力融合\n",
        "        attn = self.attn_fusion(multi_scale_feat)\n",
        "        fused = multi_scale_feat * attn\n",
        "\n",
        "        # 最终融合\n",
        "        out = self.fusion_conv(fused)\n",
        "        out = self.norm(out)\n",
        "        out = self.act(out)\n",
        "\n",
        "        return out + x  # 残差连接\n",
        "\n",
        "# GLAFormer Block - 改进版\n",
        "class GLAFormerBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, window_size=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.glam = GLAM(dim, num_heads, window_size, attn_drop=dropout)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.cgfn = CGFN(dim, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # 添加随机特征噪声\n",
        "        self.feature_noise = 0.05\n",
        "        self.apply_noise = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 注意这里使用LayerNorm，需要先调整维度(B,C,H,W)->(B,H,W,C)\n",
        "        B, C, H, W = x.shape\n",
        "        x_perm = x.permute(0, 2, 3, 1)  # [B, H, W, C]\n",
        "        x_norm = self.norm1(x_perm).permute(0, 3, 1, 2)  # 归一化后转回[B, C, H, W]\n",
        "\n",
        "        # GLAM注意力\n",
        "        glam_out = self.glam(x_norm)\n",
        "        x = x + self.dropout(glam_out)\n",
        "\n",
        "        # 在训练时添加随机特征噪声，提高鲁棒性\n",
        "        if self.training and self.apply_noise:\n",
        "            noise = torch.randn_like(x) * self.feature_noise\n",
        "            x = x + noise\n",
        "\n",
        "        # CGFN模块\n",
        "        x_perm = x.permute(0, 2, 3, 1)\n",
        "        x_norm = self.norm2(x_perm).permute(0, 3, 1, 2)\n",
        "        x = x + self.dropout(self.cgfn(x_norm))\n",
        "\n",
        "        return x\n",
        "\n",
        "# 时空双流注意力融合模块\n",
        "class DualStreamFusion(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8):\n",
        "        super().__init__()\n",
        "\n",
        "        # 单时相特征增强\n",
        "        self.t1_enhance = nn.Sequential(\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, padding=1, groups=dim),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(dim, dim, kernel_size=1),\n",
        "            nn.BatchNorm2d(dim)\n",
        "        )\n",
        "\n",
        "        self.t2_enhance = nn.Sequential(\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, padding=1, groups=dim),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(dim, dim, kernel_size=1),\n",
        "            nn.BatchNorm2d(dim)\n",
        "        )\n",
        "\n",
        "        # 跨时相注意力\n",
        "        self.cross_attn = CrossTemporalAttention(dim, num_heads)\n",
        "\n",
        "        # 特征融合\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Conv2d(dim*2, dim, kernel_size=1),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        # 添加多尺度金字塔融合\n",
        "        self.pyramid = MultiScalePyramidFusion(dim)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # 单时相特征增强\n",
        "        x1_enh = self.t1_enhance(x1)\n",
        "        x2_enh = self.t2_enhance(x2)\n",
        "\n",
        "        # 跨时相注意力\n",
        "        x1_cross, x2_cross = self.cross_attn(x1_enh, x2_enh)\n",
        "\n",
        "        # 合并增强特征\n",
        "        x1_final = x1_enh + x1_cross\n",
        "        x2_final = x2_enh + x2_cross\n",
        "\n",
        "        # 特征融合\n",
        "        fused = self.fusion(torch.cat([x1_final, x2_final], dim=1))\n",
        "\n",
        "        # 多尺度金字塔融合\n",
        "        fused = self.pyramid(fused)\n",
        "\n",
        "        return fused\n",
        "\n",
        "# 完整模型 - 改进版GLAFormer\n",
        "class GLAFormer(nn.Module):\n",
        "    def __init__(self, in_channels=198, dim=256, num_blocks=4, num_heads=8, patch_size=9,\n",
        "                 dropout=0.1, use_dual_stream=True):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.dim = dim\n",
        "        self.use_dual_stream = use_dual_stream\n",
        "\n",
        "        # 动态计算中心位置，避免硬编码\n",
        "        self.register_buffer('center', torch.tensor(patch_size // 2, dtype=torch.long))\n",
        "\n",
        "        # 改进的输入嵌入层\n",
        "        self.embed1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, dim, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        self.embed2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, dim, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # 双时相特征融合模块\n",
        "        if use_dual_stream:\n",
        "            self.dual_stream = DualStreamFusion(dim, num_heads)\n",
        "        else:\n",
        "            self.concat_conv = nn.Conv2d(dim*2, dim, kernel_size=1)\n",
        "\n",
        "        # 主干网络\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[GLAFormerBlock(dim, num_heads, dropout=dropout) for _ in range(num_blocks)]\n",
        "        )\n",
        "\n",
        "        # 多层特征融合\n",
        "        self.multi_level_fusion = nn.ModuleList([\n",
        "            nn.Conv2d(dim, dim, kernel_size=1)\n",
        "            for _ in range(num_blocks)\n",
        "        ])\n",
        "\n",
        "        # 分类头\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(dim, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 2, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        # 全局特征和中心特征提取\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # 特征增强\n",
        "        self.feat_enhance = nn.Sequential(\n",
        "            nn.Linear(2, 32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "\n",
        "        # 自适应特征融合权重\n",
        "        self.fusion_weights = nn.Parameter(torch.FloatTensor([0.6, 0.4]))\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # 检查输入\n",
        "        if x1.dim() != 4 or x2.dim() != 4:\n",
        "            raise ValueError(f\"输入维度不正确: x1={x1.shape}, x2={x2.shape}\")\n",
        "\n",
        "        # 特征嵌入\n",
        "        feat1 = self.embed1(x1)  # [B, dim, patch_size, patch_size]\n",
        "        feat2 = self.embed2(x2)  # [B, dim, patch_size, patch_size]\n",
        "\n",
        "        # 双时相特征融合\n",
        "        if self.use_dual_stream:\n",
        "            x = self.dual_stream(feat1, feat2)  # 高级双流融合\n",
        "        else:\n",
        "            x = self.concat_conv(torch.cat([feat1, feat2], dim=1))  # 简单连接\n",
        "\n",
        "        # 多层特征融合\n",
        "        multi_level_features = []\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x = block(x)\n",
        "            multi_level_features.append(self.multi_level_fusion[i](x))\n",
        "\n",
        "        # 融合多层特征\n",
        "        if len(multi_level_features) > 1:\n",
        "            # 加权融合多层特征\n",
        "            fusion_weights = F.softmax(torch.randn(len(multi_level_features)), dim=0)\n",
        "            for i, feat in enumerate(multi_level_features[1:], 1):\n",
        "                multi_level_features[0] += fusion_weights[i] * feat\n",
        "            x = multi_level_features[0]\n",
        "\n",
        "        # 分类预测\n",
        "        x = self.conv_block(x)  # [B, 2, patch_size, patch_size]\n",
        "\n",
        "        # 提取全局特征\n",
        "        global_feat = self.global_pool(x).flatten(1)  # [B, 2]\n",
        "\n",
        "        # 提取中心特征 - 使用动态计算的中心位置\n",
        "        center = self.center.item()\n",
        "        center_feat = x[:, :, center, center]  # [B, 2]\n",
        "\n",
        "        # 特征增强\n",
        "        global_feat = self.feat_enhance(global_feat)\n",
        "        center_feat = self.feat_enhance(center_feat)\n",
        "\n",
        "        # 归一化融合权重\n",
        "        fusion_weights = F.softmax(self.fusion_weights, dim=0)\n",
        "\n",
        "        # 自适应特征融合\n",
        "        output = fusion_weights[0] * global_feat + fusion_weights[1] * center_feat  # [B, 2]\n",
        "\n",
        "        return output\n",
        "\n",
        "# ===== 评估和训练函数 =====\n",
        "\n",
        "# 计算混淆矩阵和详细指标\n",
        "def compute_metrics(y_true, y_pred, threshold=0.5):\n",
        "    \"\"\"计算混淆矩阵和详细性能指标，支持不同决策阈值\"\"\"\n",
        "    if isinstance(y_pred, torch.Tensor) and y_pred.shape[1] == 2:\n",
        "        # 应用自定义阈值处理概率输出\n",
        "        probs = F.softmax(y_pred, dim=1)[:,1]  # 获取正类概率\n",
        "        y_pred_binary = (probs > threshold).long().cpu().numpy()\n",
        "    else:\n",
        "        # 如果已经是标签\n",
        "        y_pred_binary = y_pred\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred_binary)\n",
        "    try:\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "    except ValueError:\n",
        "        # 处理可能的单类情况\n",
        "        if len(cm) == 1:\n",
        "            if y_true[0] == 1:  # 所有都是正类\n",
        "                tp = cm[0, 0]\n",
        "                tn, fp, fn = 0, 0, 0\n",
        "            else:  # 所有都是负类\n",
        "                tn = cm[0, 0]\n",
        "                tp, fp, fn = 0, 0, 0\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "    # 计算各种指标\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    # 计算Kappa系数\n",
        "    pe = ((tn + fp) * (tn + fn) + (fn + tp) * (fp + tp)) / ((tp + tn + fp + fn) ** 2) if (tp + tn + fp + fn) > 0 else 0\n",
        "    kappa = (accuracy - pe) / (1 - pe) if (1 - pe) > 0 else 0\n",
        "\n",
        "    # 计算IoU\n",
        "    iou = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'confusion_matrix': cm,\n",
        "        'accuracy': accuracy * 100,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'kappa': kappa,\n",
        "        'iou': iou\n",
        "    }\n",
        "\n",
        "# 自适应寻找最佳阈值\n",
        "def find_optimal_threshold(model, data_loader, device, num_thresholds=10):\n",
        "    \"\"\"搜索最佳决策阈值\"\"\"\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for before_patch, after_patch, labels, mixup_params in data_loader:\n",
        "            before_patch = before_patch.to(device)\n",
        "            after_patch = after_patch.to(device)\n",
        "\n",
        "            outputs = model(before_patch, after_patch)\n",
        "            probs = F.softmax(outputs, dim=1)[:, 1]  # 获取正类概率\n",
        "\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # 测试不同阈值\n",
        "    thresholds = np.linspace(0.1, 0.9, num_thresholds)\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        y_pred = (np.array(all_probs) > threshold).astype(int)\n",
        "        f1 = f1_score(all_labels, y_pred)\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "\n",
        "    print(f\"找到最佳阈值: {best_threshold:.3f}，F1分数: {best_f1:.4f}\")\n",
        "    return best_threshold\n",
        "\n",
        "# 评估函数\n",
        "def evaluate(model, data_loader, criterion, device, threshold=0.5, mixup_eval=False):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_outputs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            if mixup_eval and len(batch) == 4:  # MixUp 数据\n",
        "                before_patch, after_patch, labels, mixup_params = batch\n",
        "                before_patch = before_patch.to(device)\n",
        "                after_patch = after_patch.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(before_patch, after_patch)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            else:  # 标准数据\n",
        "                before_patch, after_patch, labels, _ = batch\n",
        "                before_patch = before_patch.to(device)\n",
        "                after_patch = after_patch.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(before_patch, after_patch)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * before_patch.size(0)\n",
        "            all_outputs.append(outputs)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_loss /= len(data_loader.dataset)\n",
        "    all_outputs = torch.cat(all_outputs, dim=0)\n",
        "\n",
        "    # 计算指标\n",
        "    metrics = compute_metrics(all_labels, all_outputs, threshold)\n",
        "\n",
        "    return val_loss, metrics, all_outputs, all_labels\n",
        "\n",
        "# 学习率预热和余弦退火调度器\n",
        "class WarmupCosineScheduler:\n",
        "    def __init__(self, optimizer, warmup_epochs, total_epochs, min_lr=1e-6, warmup_method='linear'):\n",
        "        self.optimizer = optimizer\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "        self.total_epochs = total_epochs\n",
        "        self.min_lr = min_lr\n",
        "        self.warmup_method = warmup_method\n",
        "        self.base_lrs = [group['lr'] for group in optimizer.param_groups]\n",
        "\n",
        "    def step(self, epoch):\n",
        "        if epoch < self.warmup_epochs:\n",
        "            # 预热阶段\n",
        "            if self.warmup_method == 'linear':\n",
        "                # 线性预热\n",
        "                lr_scale = epoch / self.warmup_epochs\n",
        "            elif self.warmup_method == 'exp':\n",
        "                # 指数预热\n",
        "                lr_scale = (epoch / self.warmup_epochs) ** 2\n",
        "            else:\n",
        "                # 默认线性预热\n",
        "                lr_scale = epoch / self.warmup_epochs\n",
        "        else:\n",
        "            # 余弦退火\n",
        "            progress = (epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)\n",
        "            lr_scale = max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "        for i, group in enumerate(self.optimizer.param_groups):\n",
        "            group['lr'] = self.base_lrs[i] * lr_scale + self.min_lr\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    \"\"\"自定义的collate函数，用于处理包含None的batch数据\"\"\"\n",
        "    before_patches, after_patches, labels, mixup_params = zip(*batch)\n",
        "\n",
        "    # 将patches和labels转换为张量\n",
        "    before_patches = torch.stack(before_patches)\n",
        "    after_patches = torch.stack(after_patches)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    # 处理mixup参数\n",
        "    if all(p is None for p in mixup_params):\n",
        "        mixup_params = None\n",
        "    else:\n",
        "        valid_params = [p for p in mixup_params if p is not None]\n",
        "        if valid_params:\n",
        "            # 合并所有mixup参数\n",
        "            mixup_params = {\n",
        "                'lam': torch.tensor([p['lam'] for p in valid_params]),\n",
        "                'other_label': torch.tensor([p['other_label'] for p in valid_params])\n",
        "            }\n",
        "        else:\n",
        "            mixup_params = None\n",
        "\n",
        "    return before_patches, after_patches, labels, mixup_params\n",
        "\n",
        "def main():\n",
        "    # 设置随机种子以确保可重复性\n",
        "    torch.manual_seed(42)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # 配置参数\n",
        "    in_channels = 198  # 高光谱数据波段数，根据数据集调整\n",
        "    patch_size = 9\n",
        "    batch_size = 256\n",
        "    num_epochs = 100\n",
        "    learning_rate = 0.0005\n",
        "    weight_decay = 5e-5\n",
        "    warmup_epochs = 5  # 学习率预热epochs\n",
        "    model_save_path = 'best_glaformer_model.pth'\n",
        "    dropout = 0.2\n",
        "    use_dual_stream = True  # 是否使用双时相流模块\n",
        "    use_focal_loss = True   # 是否使用Focal Loss\n",
        "    use_mixup = True        # 是否使用MixUp\n",
        "    use_sampler = True      # 是否使用加权采样\n",
        "\n",
        "    # 检查CUDA可用性\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"使用设备: {device}\")\n",
        "\n",
        "    # 加载数据集\n",
        "    try:\n",
        "        train_dataset = HSIChangeDetectionDataset(\n",
        "            '/content/drive/MyDrive/dataset zuixin/river_before.mat',\n",
        "            '/content/drive/MyDrive/dataset zuixin/river_after.mat',\n",
        "            '/content/drive/MyDrive/dataset zuixin/groundtruth.mat',\n",
        "            patch_size=patch_size,\n",
        "            mode='train',\n",
        "            augment=True\n",
        "        )\n",
        "\n",
        "        val_dataset = HSIChangeDetectionDataset(\n",
        "            '/content/drive/MyDrive/dataset zuixin/river_before.mat',\n",
        "            '/content/drive/MyDrive/dataset zuixin/river_after.mat',\n",
        "            '/content/drive/MyDrive/dataset zuixin/groundtruth.mat',\n",
        "            patch_size=patch_size,\n",
        "            mode='val'\n",
        "        )\n",
        "\n",
        "        test_dataset = HSIChangeDetectionDataset(\n",
        "            '/content/drive/MyDrive/dataset zuixin/river_before.mat',\n",
        "            '/content/drive/MyDrive/dataset zuixin/river_after.mat',\n",
        "            '/content/drive/MyDrive/dataset zuixin/groundtruth.mat',\n",
        "            patch_size=patch_size,\n",
        "            mode='test'\n",
        "        )\n",
        "\n",
        "        # 检查数据集维度\n",
        "        sample = train_dataset[0]\n",
        "        if isinstance(sample, tuple) and len(sample) >= 3:\n",
        "            in_channels = sample[0].shape[0]  # 动态获取输入通道数\n",
        "            print(f\"检测到输入通道数: {in_channels}\")\n",
        "            print(f\"数据样本形状: before={sample[0].shape}, after={sample[1].shape}, label={sample[2]}\")\n",
        "\n",
        "        # 创建加权采样器 - 处理类别不平衡\n",
        "        if use_sampler:\n",
        "            # 获取训练集的所有标签\n",
        "            train_labels = [train_dataset[i][2] for i in range(len(train_dataset))]\n",
        "\n",
        "            # 计算样本权重：少数类样本获得更高权重\n",
        "            class_counts = Counter(train_labels)\n",
        "            num_samples = len(train_labels)\n",
        "\n",
        "            class_weights = {class_id: num_samples / (len(class_counts) * count)\n",
        "                             for class_id, count in class_counts.items()}\n",
        "\n",
        "            # 为每个样本分配权重\n",
        "            sample_weights = [class_weights[label] for label in train_labels]\n",
        "            sampler = WeightedRandomSampler(\n",
        "                weights=sample_weights,\n",
        "                num_samples=len(train_dataset),\n",
        "                replacement=True\n",
        "            )\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                    sampler=sampler, num_workers=2, pin_memory=True, collate_fn=custom_collate_fn)\n",
        "            print(\"使用加权采样器处理类别不平衡\")\n",
        "        else:\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                    shuffle=True, num_workers=2, pin_memory=True, collate_fn=custom_collate_fn)\n",
        "\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
        "                               shuffle=False, num_workers=2, pin_memory=True, collate_fn=custom_collate_fn)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                shuffle=False, num_workers=2, pin_memory=True, collate_fn=custom_collate_fn)\n",
        "\n",
        "        print(f\"训练样本数: {len(train_dataset)}\")\n",
        "        print(f\"验证样本数: {len(val_dataset)}\")\n",
        "        print(f\"测试样本数: {len(test_dataset)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"加载数据集时出错: {e}\")\n",
        "        return\n",
        "\n",
        "    # 初始化模型\n",
        "    model = GLAFormer(\n",
        "        in_channels=in_channels,\n",
        "        dim=256,\n",
        "        num_blocks=4,\n",
        "        num_heads=8,\n",
        "        patch_size=patch_size,\n",
        "        dropout=dropout,\n",
        "        use_dual_stream=use_dual_stream\n",
        "    ).to(device)\n",
        "\n",
        "    print(f\"模型初始化完成，参数量: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "    # 动态设置类别权重 - 根据训练数据分布计算\n",
        "    neg_weight = 1.0\n",
        "    pos_weight = train_dataset.subset_class_counts[0] / max(1, train_dataset.subset_class_counts[1])  # 正样本权重\n",
        "    class_weights = torch.tensor([neg_weight, pos_weight]).to(device)\n",
        "    print(f\"类别权重: {class_weights.cpu().numpy()}\")\n",
        "\n",
        "    # 选择损失函数\n",
        "    if use_focal_loss:\n",
        "        criterion = FocalLoss(alpha=class_weights, gamma=2.0)\n",
        "        print(\"使用Focal Loss\")\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "        print(\"使用加权交叉熵损失\")\n",
        "\n",
        "    # 优化器 - 使用AdamW而非Adam\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # 学习率调度器 - 使用预热和余弦退火\n",
        "    lr_scheduler = WarmupCosineScheduler(\n",
        "        optimizer,\n",
        "        warmup_epochs=warmup_epochs,\n",
        "        total_epochs=num_epochs,\n",
        "        warmup_method='exp'  # 使用指数预热而非线性预热\n",
        "    )\n",
        "\n",
        "    # 训练循环\n",
        "    best_val_f1 = 0.0\n",
        "    patience = 15  # 早停耐心值 - 增加以允许模型充分探索\n",
        "    counter = 0    # 早停计数器\n",
        "    best_threshold = 0.5  # 初始决策阈值\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # 更新学习率\n",
        "        lr_scheduler.step(epoch)\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        # 训练阶段\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        batch_count = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            # 处理MixUp数据\n",
        "            if use_mixup and len(batch) == 4:\n",
        "                before_patch, after_patch, labels, mixup_params = batch\n",
        "                before_patch = before_patch.to(device)\n",
        "                after_patch = after_patch.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(before_patch, after_patch)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            else:  # 处理标准数据\n",
        "                before_patch, after_patch, labels, _ = batch\n",
        "                before_patch = before_patch.to(device)\n",
        "                after_patch = after_patch.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(before_patch, after_patch)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # 梯度裁剪，防止梯度爆炸\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * before_patch.size(0)\n",
        "            batch_count += 1\n",
        "\n",
        "            # 打印进度\n",
        "            if batch_count % 20 == 0:\n",
        "                print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_count}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        # 验证阶段\n",
        "        val_loss, val_metrics, val_outputs, val_labels = evaluate(\n",
        "            model, val_loader, criterion, device, threshold=best_threshold, mixup_eval=use_mixup\n",
        "        )\n",
        "\n",
        "        # 每5个epoch寻找最佳阈值\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            best_threshold = find_optimal_threshold(model, val_loader, device)\n",
        "            # 使用新阈值重新评估\n",
        "            _, val_metrics, _, _ = evaluate(\n",
        "                model, val_loader, criterion, device, threshold=best_threshold, mixup_eval=use_mixup\n",
        "            )\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, LR: {current_lr:.6f}, 阈值: {best_threshold:.3f}')\n",
        "        print(f'  Train Loss: {train_loss:.4f}')\n",
        "        print(f'  Val Loss: {val_loss:.4f}, Acc: {val_metrics[\"accuracy\"]:.2f}%, F1: {val_metrics[\"f1\"]:.4f}, Kappa: {val_metrics[\"kappa\"]:.4f}')\n",
        "        print(f'  Val Confusion Matrix:\\n{val_metrics[\"confusion_matrix\"]}')\n",
        "\n",
        "        # 保存最佳模型（基于F1分数）\n",
        "        if val_metrics[\"f1\"] > best_val_f1:\n",
        "            best_val_f1 = val_metrics[\"f1\"]\n",
        "            counter = 0\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_loss': val_loss,\n",
        "                'val_f1': val_metrics[\"f1\"],\n",
        "                'val_metrics': val_metrics,\n",
        "                'threshold': best_threshold,\n",
        "            }, model_save_path)\n",
        "            print(f'  模型已保存: val_f1 从 {best_val_f1-val_metrics[\"f1\"]:.4f} 提升到 {val_metrics[\"f1\"]:.4f}')\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f'  F1未提升: {counter}/{patience}')\n",
        "\n",
        "        # 早停\n",
        "        if counter >= patience:\n",
        "            print(f'早停: 验证F1已经{patience}个epoch没有提升')\n",
        "            break\n",
        "\n",
        "    # 测试阶段\n",
        "    # 加载最佳模型\n",
        "    checkpoint = torch.load(model_save_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    best_threshold = checkpoint['threshold']\n",
        "    print(f\"加载最佳模型（epoch {checkpoint['epoch']+1}，验证F1: {checkpoint['val_f1']:.4f}，阈值: {best_threshold:.3f}）\")\n",
        "\n",
        "    # 在测试集上评估\n",
        "    test_loss, test_metrics, _, _ = evaluate(\n",
        "        model, test_loader, criterion, device, threshold=best_threshold, mixup_eval=False\n",
        "    )\n",
        "\n",
        "    print(\"\\n最终测试结果:\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_metrics['accuracy']:.2f}%\")\n",
        "    print(f\"Test Precision: {test_metrics['precision']:.4f}\")\n",
        "    print(f\"Test Recall: {test_metrics['recall']:.4f}\")\n",
        "    print(f\"Test F1 Score: {test_metrics['f1']:.4f}\")\n",
        "    print(f\"Test Kappa: {test_metrics['kappa']:.4f}\")\n",
        "    print(f\"Test IoU: {test_metrics['iou']:.4f}\")\n",
        "    print(f\"Test Confusion Matrix:\\n{test_metrics['confusion_matrix']}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD7NkbDviXR2",
        "outputId": "63c693bd-5e33-416b-cdde-40d7a474f112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用设备: cuda\n",
            "标签中的唯一值: [  0 255]\n",
            "类别分布 - 未变化: 96694, 变化: 9321\n",
            "train 集合 - 未变化: 67685, 变化: 6524\n",
            "标签中的唯一值: [  0 255]\n",
            "类别分布 - 未变化: 96694, 变化: 9321\n",
            "val 集合 - 未变化: 14504, 变化: 1398\n",
            "标签中的唯一值: [  0 255]\n",
            "类别分布 - 未变化: 96694, 变化: 9321\n",
            "test 集合 - 未变化: 14505, 变化: 1399\n",
            "检测到输入通道数: 198\n",
            "数据样本形状: before=torch.Size([198, 9, 9]), after=torch.Size([198, 9, 9]), label=1\n",
            "使用加权采样器处理类别不平衡\n",
            "训练样本数: 74209\n",
            "验证样本数: 15902\n",
            "测试样本数: 15904\n",
            "模型初始化完成，参数量: 34,125,222\n",
            "类别权重: [ 1.      10.37477]\n",
            "使用Focal Loss\n",
            "Epoch 1/100, Batch 20/290, Loss: 3.9334\n",
            "Epoch 1/100, Batch 40/290, Loss: 3.7414\n",
            "Epoch 1/100, Batch 60/290, Loss: 2.8498\n",
            "Epoch 1/100, Batch 80/290, Loss: 3.5809\n",
            "Epoch 1/100, Batch 100/290, Loss: 3.2674\n",
            "Epoch 1/100, Batch 120/290, Loss: 3.1210\n",
            "Epoch 1/100, Batch 140/290, Loss: 3.1948\n",
            "Epoch 1/100, Batch 160/290, Loss: 2.8224\n",
            "Epoch 1/100, Batch 180/290, Loss: 2.7188\n",
            "Epoch 1/100, Batch 200/290, Loss: 2.6221\n",
            "Epoch 1/100, Batch 220/290, Loss: 2.8675\n",
            "Epoch 1/100, Batch 240/290, Loss: 2.4869\n",
            "Epoch 1/100, Batch 260/290, Loss: 2.3072\n",
            "Epoch 1/100, Batch 280/290, Loss: 2.5297\n",
            "Epoch 1/100, LR: 0.000001, 阈值: 0.500\n",
            "  Train Loss: 2.9508\n",
            "  Val Loss: 0.7217, Acc: 8.79%, F1: 0.1616, Kappa: 0.0000\n",
            "  Val Confusion Matrix:\n",
            "[[    0 14504]\n",
            " [    0  1398]]\n",
            "  模型已保存: val_f1 从 0.0000 提升到 0.1616\n",
            "Epoch 2/100, Batch 20/290, Loss: 1.5679\n",
            "Epoch 2/100, Batch 40/290, Loss: 1.1658\n",
            "Epoch 2/100, Batch 60/290, Loss: 1.1116\n",
            "Epoch 2/100, Batch 80/290, Loss: 0.9705\n",
            "Epoch 2/100, Batch 100/290, Loss: 1.0190\n",
            "Epoch 2/100, Batch 120/290, Loss: 0.8907\n",
            "Epoch 2/100, Batch 140/290, Loss: 0.9416\n",
            "Epoch 2/100, Batch 160/290, Loss: 1.0457\n",
            "Epoch 2/100, Batch 180/290, Loss: 0.8902\n",
            "Epoch 2/100, Batch 200/290, Loss: 0.7932\n",
            "Epoch 2/100, Batch 220/290, Loss: 0.8970\n",
            "Epoch 2/100, Batch 240/290, Loss: 0.9120\n",
            "Epoch 2/100, Batch 260/290, Loss: 0.8513\n",
            "Epoch 2/100, Batch 280/290, Loss: 0.8490\n",
            "Epoch 2/100, LR: 0.000021, 阈值: 0.500\n",
            "  Train Loss: 1.0113\n",
            "  Val Loss: 1.0318, Acc: 8.79%, F1: 0.1616, Kappa: 0.0000\n",
            "  Val Confusion Matrix:\n",
            "[[    0 14504]\n",
            " [    0  1398]]\n",
            "  F1未提升: 1/15\n"
          ]
        }
      ]
    }
  ]
}
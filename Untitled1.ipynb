{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1xnOCF5EBjDDapoE7LJOccB0nM1yz4Ir5",
      "authorship_tag": "ABX9TyPDlUTFH6tVjYYHL+40UGWM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caaszj/GLAFormer/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "import os\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# 数据预处理和加载\n",
        "class HSIChangeDetectionDataset(Dataset):\n",
        "    def __init__(self, before_path, after_path, gt_path, patch_size=9, mode='train'):\n",
        "        self.before = self.load_mat(before_path)  # (H, W, C)\n",
        "        self.after = self.load_mat(after_path)\n",
        "        self.gt = self.load_gt(gt_path)  # (H, W)\n",
        "\n",
        "        # 归一化\n",
        "        self.before = (self.before - self.before.min()) / (self.before.max() - self.before.min())\n",
        "        self.after = (self.after - self.after.min()) / (self.after.max() - self.after.min())\n",
        "\n",
        "        self.patch_size = patch_size\n",
        "        self.half = patch_size // 2\n",
        "        self.mode = mode\n",
        "\n",
        "        # 生成有效位置索引\n",
        "        self.coords = self.get_valid_coords()\n",
        "\n",
        "        # 划分训练/验证/测试集\n",
        "        np.random.seed(42)  # 设置随机种子以确保可重复性\n",
        "        idx = np.random.permutation(len(self.coords))  # 随机打乱索引\n",
        "        train_num = int(len(idx) * 0.7)  # 训练集占70%\n",
        "        val_num = int(len(idx) * 0.15)  # 验证集占15%\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.coords = self.coords[idx[:train_num]]  # 取前70%作为训练集\n",
        "        elif mode == 'val':\n",
        "            self.coords = self.coords[idx[train_num:train_num + val_num]]  # 取接下来的15%作为验证集\n",
        "        else:\n",
        "            self.coords = self.coords[idx[train_num + val_num:]]  # 剩下的15%作为测试集\n",
        "\n",
        "    def load_mat(self, path):\n",
        "        mat = loadmat(path)\n",
        "        # 获取.mat文件中的第一个键，假设它是数据键\n",
        "        keys = [k for k in mat.keys() if not k.startswith('__')]\n",
        "        if 'river_before' in mat:\n",
        "            return mat['river_before'].astype(np.float32)\n",
        "        elif 'river_after' in mat:\n",
        "            return mat['river_after'].astype(np.float32)\n",
        "        elif len(keys) > 0:\n",
        "            return mat[keys[0]].astype(np.float32)\n",
        "        else:\n",
        "            raise ValueError(f\"无法从{path}加载数据\")\n",
        "\n",
        "    def load_gt(self, path):\n",
        "        mat = loadmat(path)\n",
        "        keys = [k for k in mat.keys() if not k.startswith('__')]\n",
        "        if 'lakelabel_v1' in mat:\n",
        "            return mat['lakelabel_v1'].astype(np.int64)\n",
        "        elif len(keys) > 0:\n",
        "            return mat[keys[0]].astype(np.int64)\n",
        "        else:\n",
        "            raise ValueError(f\"无法从{path}加载标签\")\n",
        "\n",
        "    def get_valid_coords(self):\n",
        "        H, W = self.gt.shape\n",
        "        coords = []\n",
        "        for i in range(self.half, H-self.half):\n",
        "            for j in range(self.half, W-self.half):\n",
        "                if self.gt[i, j] in [0, 255]:  # 只处理有效像素\n",
        "                    coords.append((i, j))\n",
        "        return np.array(coords)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.coords)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        i, j = self.coords[idx]\n",
        "        # 提取双时相patch\n",
        "        before_patch = self.before[i-self.half:i+self.half+1, j-self.half:j+self.half+1, :]\n",
        "        after_patch = self.after[i-self.half:i+self.half+1, j-self.half:j+self.half+1, :]\n",
        "        # 转为CHW格式\n",
        "        before_patch = torch.from_numpy(before_patch).permute(2,0,1).float()\n",
        "        after_patch = torch.from_numpy(after_patch).permute(2,0,1).float()\n",
        "        label = self.gt[i, j] // 255  # 将255映射为1\n",
        "\n",
        "        return before_patch, after_patch, label\n",
        "\n",
        "# GLAM模块实现\n",
        "class GLAM(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, window_size=3):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.split_dim = dim // 2  # 明确分割维度\n",
        "        self.num_heads_local = num_heads // 2\n",
        "        self.head_dim_local = self.split_dim // self.num_heads_local  # 正确计算头维度\n",
        "        self.window_size = window_size\n",
        "\n",
        "        # Local分支\n",
        "        self.local_qkv = nn.Conv2d(self.split_dim, self.split_dim*3, kernel_size=1)\n",
        "\n",
        "        # Global分支\n",
        "        self.global_q = nn.Conv2d(self.split_dim, self.split_dim, kernel_size=1)\n",
        "        self.global_kv = nn.Conv2d(self.split_dim, self.split_dim*2, kernel_size=1)\n",
        "\n",
        "        self.proj = nn.Conv2d(dim, dim, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        x_local, x_global = torch.split(x, self.split_dim, dim=1)\n",
        "\n",
        "        # Local Attention\n",
        "        qkv = self.local_qkv(x_local)  # [B, 3*split_dim, H, W]\n",
        "        q, k, v = torch.chunk(qkv, 3, dim=1)  # 各为split_dim\n",
        "        q = q.view(B, self.num_heads_local, self.head_dim_local, H*W)\n",
        "        k = k.view(B, self.num_heads_local, self.head_dim_local, H*W)\n",
        "        v = v.view(B, self.num_heads_local, self.head_dim_local, H*W)\n",
        "\n",
        "        attn = (q.transpose(-2, -1) @ k) / math.sqrt(self.head_dim_local)\n",
        "        local_out = (v @ attn.softmax(dim=-1).transpose(-2, -1)).view(B, self.split_dim, H, W)\n",
        "\n",
        "        # Global Attention\n",
        "        x_pool = F.avg_pool2d(x_global, self.window_size)\n",
        "        pool_H, pool_W = x_pool.shape[2], x_pool.shape[3]\n",
        "        kv = self.global_kv(x_pool)\n",
        "        k_g, v_g = torch.chunk(kv, 2, dim=1)\n",
        "\n",
        "        q_g = self.global_q(x_global).view(B, self.num_heads_local, self.head_dim_local, H*W)\n",
        "        k_g = k_g.view(B, self.num_heads_local, self.head_dim_local, pool_H*pool_W)\n",
        "        v_g = v_g.view(B, self.num_heads_local, self.head_dim_local, pool_H*pool_W)\n",
        "\n",
        "        attn_g = (q_g.transpose(-2, -1) @ k_g) / math.sqrt(self.head_dim_local)\n",
        "        global_out = (v_g @ attn_g.softmax(dim=-1).transpose(-2, -1)).view(B, self.split_dim, H, W)\n",
        "\n",
        "        return self.proj(torch.cat([local_out, global_out], dim=1))\n",
        "\n",
        "# CGFN模块实现\n",
        "class CGFN(nn.Module):\n",
        "    def __init__(self, dim, expansion=4):\n",
        "        super().__init__()\n",
        "        hidden_dim = dim * expansion\n",
        "\n",
        "        self.conv1 = nn.Conv2d(dim, hidden_dim, 1)\n",
        "        self.dwconv3 = nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1, groups=hidden_dim)\n",
        "        self.dwconv5 = nn.Conv2d(hidden_dim, hidden_dim, 5, padding=2, groups=hidden_dim)\n",
        "        self.conv2 = nn.Conv2d(hidden_dim*2, dim, 1)\n",
        "\n",
        "        self.gate1 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.gate2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x1 = self.dwconv3(x)\n",
        "        x2 = self.dwconv5(x)\n",
        "\n",
        "        g1 = self.gate1(x1)\n",
        "        g2 = self.gate2(x2)\n",
        "\n",
        "        x1 = x1 * g1 + x2\n",
        "        x2 = x2 * g2 + x1\n",
        "        x = torch.cat([x1, x2], dim=1)\n",
        "        return self.conv2(x)\n",
        "\n",
        "# 辅助模块\n",
        "class LambdaLayer(nn.Module):\n",
        "    def __init__(self, lambd):\n",
        "        super().__init__()\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lambd(x)\n",
        "\n",
        "# GLAFormer Block\n",
        "class GLAFormerBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, window_size=3):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.glam = GLAM(dim, num_heads, window_size)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.cgfn = CGFN(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 注意这里使用LayerNorm，需要先调整维度(B,C,H,W)->(B,H,W,C)\n",
        "        x_norm = self.norm1(x.permute(0,2,3,1)).permute(0,3,1,2)\n",
        "        x = x + self.glam(x_norm)\n",
        "\n",
        "        x_norm = self.norm2(x.permute(0,2,3,1)).permute(0,3,1,2)\n",
        "        x = x + self.cgfn(x_norm)\n",
        "        return x\n",
        "\n",
        "# 完整模型\n",
        "class GLAFormer(nn.Module):\n",
        "    def __init__(self, in_channels=198, dim=256, num_blocks=4, num_heads=8, patch_size=9):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.center = patch_size // 2  # 预计算中心位置索引\n",
        "\n",
        "        # 输入嵌入层\n",
        "        self.embed = nn.Sequential(\n",
        "            nn.Conv2d(in_channels*2, dim, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 主干网络\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[GLAFormerBlock(dim, num_heads) for _ in range(num_blocks)]\n",
        "        )\n",
        "\n",
        "        # 修正后的分类头\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(dim, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 2, kernel_size=1)  # 输出通道数为2\n",
        "        )\n",
        "        self.global_pool = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        self.center_extract = LambdaLayer(lambda x: x[:, :, self.center, self.center])\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # 双时相特征融合\n",
        "        x = torch.cat([x1, x2], dim=1)  # [B, 2*in_channels, patch_size, patch_size]\n",
        "        x = self.embed(x)               # [B, dim, patch_size, patch_size]\n",
        "        x = self.blocks(x)              # [B, dim, patch_size, patch_size]\n",
        "\n",
        "        x = self.conv_block(x)          # [B, 2, patch_size, patch_size]\n",
        "\n",
        "        # 并行处理两种特征提取方式\n",
        "        global_feat = self.global_pool(x)  # [B, 2]\n",
        "        center_feat = self.center_extract(x)  # [B, 2]\n",
        "\n",
        "        # 特征融合（加权平均）\n",
        "        return 0.6 * global_feat + 0.4 * center_feat  # [B, 2]\n",
        "\n",
        "# 评估函数\n",
        "def evaluate(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for before_patch, after_patch, labels in data_loader:\n",
        "            before_patch = before_patch.to(device)\n",
        "            after_patch = after_patch.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(before_patch, after_patch)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * before_patch.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_loss /= len(data_loader.dataset)\n",
        "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels)) * 100\n",
        "    precision = precision_score(all_labels, all_preds, average='binary', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='binary', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='binary', zero_division=0)\n",
        "\n",
        "    return val_loss, accuracy, precision, recall, f1\n",
        "\n",
        "def main():\n",
        "    # 设置随机种子以确保可重复性\n",
        "    torch.manual_seed(42)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # 配置参数\n",
        "    in_channels = 198  # 实际高光谱数据的波段数，需要根据具体数据集调整\n",
        "    patch_size = 9\n",
        "    batch_size = 512\n",
        "    num_epochs = 50\n",
        "    learning_rate = 0.0006\n",
        "    weight_decay = 1e-4\n",
        "    model_save_path = 'best_model.pth'\n",
        "\n",
        "    # 检查CUDA可用性\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # 加载数据集\n",
        "    try:\n",
        "        train_dataset = HSIChangeDetectionDataset(\n",
        "            '/content/drive/MyDrive/dataset zuixin/river_before.mat',\n",
        "            '/content/drive/MyDrive/dataset zuixin/river_after.mat',\n",
        "            '/content/drive/MyDrive/dataset zuixin/groundtruth.mat',\n",
        "            patch_size=patch_size,\n",
        "            mode='train'\n",
        "        )\n",
        "\n",
        "        val_dataset = HSIChangeDetectionDataset(\n",
        "            '/content/drive/MyDrive/dataset zuixin/river_before.mat',\n",
        "            '/content/drive/MyDrive/dataset zuixin/river_after.mat',\n",
        "            '/content/drive/MyDrive/dataset zuixin/groundtruth.mat',\n",
        "            patch_size=patch_size,\n",
        "            mode='val'\n",
        "        )\n",
        "\n",
        "        test_dataset = HSIChangeDetectionDataset(\n",
        "            '/content/drive/MyDrive/dataset zuixin/river_before.mat',\n",
        "            '/content/drive/MyDrive/dataset zuixin/river_after.mat',\n",
        "            '/content/drive/MyDrive/dataset zuixin/groundtruth.mat',\n",
        "            patch_size=patch_size,\n",
        "            mode='test'\n",
        "        )\n",
        "\n",
        "        # 检查数据集维度\n",
        "        sample = train_dataset[0]\n",
        "        in_channels = sample[0].shape[0]  # 动态获取输入通道数\n",
        "        print(f\"检测到输入通道数: {in_channels}\")\n",
        "        print(f\"数据样本形状: before={sample[0].shape}, after={sample[1].shape}, label={sample[2]}\")\n",
        "\n",
        "        # 创建数据加载器\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "        print(f\"训练样本数: {len(train_dataset)}\")\n",
        "        print(f\"验证样本数: {len(val_dataset)}\")\n",
        "        print(f\"测试样本数: {len(test_dataset)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"加载数据集时出错: {e}\")\n",
        "        return\n",
        "\n",
        "    # 初始化模型\n",
        "    model = GLAFormer(in_channels=in_channels, dim=256, num_blocks=4, num_heads=8, patch_size=patch_size).to(device)\n",
        "\n",
        "    # 类别不平衡处理\n",
        "    # 根据数据集中变化和未变化像素的比例调整权重\n",
        "    # 假设变化像素较少，给予更高的权重\n",
        "    criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 10.0]).to(device))\n",
        "\n",
        "    # 优化器和学习率调度器\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "    # 训练循环\n",
        "    best_val_loss = float('inf')\n",
        "    best_f1 = 0.0\n",
        "    patience = 10  # 早停耐心值\n",
        "    counter = 0    # 早停计数器\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # 训练阶段\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for before_patch, after_patch, labels in train_loader:\n",
        "            before_patch = before_patch.to(device)\n",
        "            after_patch = after_patch.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(before_patch, after_patch)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * before_patch.size(0)\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        # 验证阶段\n",
        "        val_loss, val_accuracy, val_precision, val_recall, val_f1 = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        # 学习率调整\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'  Train Loss: {train_loss:.4f}')\n",
        "        print(f'  Val Loss: {val_loss:.4f}, Acc: {val_accuracy:.2f}%, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}')\n",
        "\n",
        "        # 保存最佳模型（基于验证损失或F1分数）\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            counter = 0\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_loss': val_loss,\n",
        "                'val_f1': val_f1,\n",
        "            }, model_save_path)\n",
        "            print(f'  模型已保存: val_f1 从 {best_f1-val_f1:.4f} 提升到 {val_f1:.4f}')\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f'  F1未提升: {counter}/{patience}')\n",
        "\n",
        "        # 早停\n",
        "        if counter >= patience:\n",
        "            print(f'早停: 验证F1已经{patience}个epoch没有提升')\n",
        "            break\n",
        "\n",
        "    # 测试阶段\n",
        "    # 加载最佳模型\n",
        "    checkpoint = torch.load(model_save_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"加载最佳模型（epoch {checkpoint['epoch']+1}，验证F1: {checkpoint['val_f1']:.4f}）\")\n",
        "\n",
        "    # 在测试集上评估\n",
        "    test_loss, test_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    print(\"\\n最终测试结果:\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "    print(f\"Test Precision: {test_precision:.4f}\")\n",
        "    print(f\"Test Recall: {test_recall:.4f}\")\n",
        "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pB0tgs_Kc_e",
        "outputId": "893e8358-ae53-4946-e2cf-a77db50beb77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "检测到输入通道数: 198\n",
            "数据样本形状: before=torch.Size([198, 9, 9]), after=torch.Size([198, 9, 9]), label=0\n",
            "训练样本数: 74210\n",
            "验证样本数: 15902\n",
            "测试样本数: 15903\n",
            "Epoch 1/50:\n",
            "  Train Loss: 0.2447\n",
            "  Val Loss: 0.1485, Acc: 91.96%, Precision: 0.5211, Recall: 0.9770, F1: 0.6797\n",
            "  模型已保存: val_f1 从 0.0000 提升到 0.6797\n",
            "Epoch 2/50:\n",
            "  Train Loss: 0.1359\n",
            "  Val Loss: 0.1479, Acc: 96.23%, Precision: 0.7242, Recall: 0.9186, F1: 0.8099\n",
            "  模型已保存: val_f1 从 0.0000 提升到 0.8099\n"
          ]
        }
      ]
    }
  ]
}
{"cells":[{"cell_type":"code","metadata":{"id":"4C066F2863894600ADC78C2DDEC87224","notebookId":"67e276634dbc50a36ceea9de","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"import torch  # PyTorch深度学习框架\nfrom scipy.io import loadmat  # 用于加载MATLAB .mat文件\nfrom pathlib import Path  # 路径处理库\nimport numpy as np  # 科学计算库\nfrom torch.utils.data import DataLoader, TensorDataset  # 数据加载和数据集创建工具\nfrom sklearn.model_selection import train_test_split  # 数据集划分工具\nimport matplotlib.pyplot as plt  # 可视化库\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix  # 评估指标计算工具\nimport seaborn as sns  # 高级可视化库\nimport os  # 操作系统接口\nimport torch.nn as nn  # PyTorch神经网络模块\nimport torch.nn.functional as F  # PyTorch函数模块\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau  # 导入学习率调度器\n\n# ============== 数据准备阶段 ==============\n\n# 定义数据路径和模型保存路径\nbase_path = Path('/home/mw/input/re14334')  # 数据集路径\nsave_path = Path('checkpoints')  # 模型保存路径\nsave_path.mkdir(exist_ok=True)  # 创建保存目录，如果已存在则不报错\n\n# 加载 .mat 文件\n# river_before: 变化前的河流数据，形状为(463, 241, 198)，表示高度、宽度和光谱波段数\nbefore_data = loadmat(base_path / 'river_before.mat')['river_before']  \n# river_after: 变化后的河流数据，形状与before_data相同\nafter_data = loadmat(base_path / 'river_after.mat')['river_after']     \n# groundtruth: 变化标注数据，形状为(463, 241)，二维掩码，255表示变化区域\ngt_data = loadmat(base_path / 'groundtruth.mat')['lakelabel_v1']      \n\n# 数据类型转换：将数据转换为PyTorch张量，并设定为float32类型以便计算\nbefore_data = torch.tensor(before_data, dtype=torch.float32)\nafter_data = torch.tensor(after_data, dtype=torch.float32)\ngt_data = torch.tensor(gt_data, dtype=torch.float32)\n\n# 检查数据范围并打印\nprint(f\"Before Data Range: {before_data.min().item()} to {before_data.max().item()}\")\nprint(f\"After Data Range: {after_data.min().item()} to {after_data.max().item()}\")\nprint(f\"Ground Truth Unique Values: {torch.unique(gt_data)}\")\n\n# 改进的归一化方法：按通道归一化\ndef normalize_per_channel(data):\n    \"\"\"按通道执行归一化，更适合多光谱/高光谱数据\"\"\"\n    result = data.clone()\n    # 对最后一个维度（通道）进行归一化\n    for c in range(data.shape[2]):\n        channel = data[:, :, c]\n        channel_min = channel.min()\n        channel_max = channel.max()\n        if channel_max > channel_min:  # 避免除以零\n            result[:, :, c] = (channel - channel_min) / (channel_max - channel_min)\n    return result\n\nbefore_data = normalize_per_channel(before_data)\nafter_data = normalize_per_channel(after_data)\n\n# 将标注数据转换为二值掩码：255 -> 1, 其他 -> 0\ngt_data = (gt_data == 255).float()\n\n# 调整数据维度顺序以符合PyTorch的约定(通道,高度,宽度)\n# 将原始数据(H,W,C)转换为(C,H,W)\nbefore_data = before_data.permute(2, 0, 1)  # 形状变为: (198, 463, 241)\nafter_data = after_data.permute(2, 0, 1)    # 形状变为: (198, 463, 241)\ngt_data = gt_data.unsqueeze(0)              # 添加通道维度，形状变为: (1, 463, 241)\n\n# 特征选择：选择更具辨别力的波段（可以使用专家知识或自动选择）\n# 这里简单假设对河流变化最敏感的是前100个波段\nselected_bands = list(range(100))  # 假设前100个波段最相关\nbefore_data = before_data[selected_bands]\nafter_data = after_data[selected_bands]\n\nprint(f\"数据形状 - Before: {before_data.shape}, After: {after_data.shape}, GT: {gt_data.shape}\")\n\n# 改进的patch提取：使用重叠的patch，步长小于patch大小\ndef extract_patches_with_overlap(image, patch_size=64, stride=32):\n    \"\"\"\n    使用重叠的方式提取patches，提高边界区域的预测准确度\n    \n    参数:\n        image: 输入图像张量，形状为(C,H,W)\n        patch_size: 每个patch的大小\n        stride: 相邻patches的步长\n    \"\"\"\n    patches = []\n    positions = []  # 记录每个patch的位置\n    \n    for i in range(0, image.shape[1] - patch_size + 1, stride):\n        for j in range(0, image.shape[2] - patch_size + 1, stride):\n            patch = image[:, i:i+patch_size, j:j+patch_size]\n            patches.append(patch)\n            positions.append((i, j))\n            \n    return torch.stack(patches), positions\n\n# 使用重叠的patch提取\npatch_size = 64\nstride = 32  # 步长为patch大小的一半，产生重叠\nbefore_patches, patch_positions = extract_patches_with_overlap(before_data, patch_size, stride)\nafter_patches, _ = extract_patches_with_overlap(after_data, patch_size, stride)\ngt_patches, _ = extract_patches_with_overlap(gt_data, patch_size, stride)\n\nprint(f\"提取的patch数量: {len(before_patches)}\")\nprint(f\"Patch形状 - Before: {before_patches.shape}, GT: {gt_patches.shape}\")\n\n# 创建数据集并划分\ndataset = TensorDataset(before_patches, after_patches, gt_patches)\ntrain_dataset, temp_dataset = train_test_split(dataset, test_size=0.3, random_state=42)\nval_dataset, test_dataset = train_test_split(temp_dataset, test_size=0.5, random_state=42)\n\n# 使用较小的batch_size，避免内存问题\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n\n# ============== 改进的模型定义 ==============\n\nclass ConvBlock(nn.Module):\n    \"\"\"基本卷积块：Conv2d + BatchNorm + ReLU\"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n        super(ConvBlock, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n        self.bn = nn.BatchNorm2d(out_channels)\n        \n    def forward(self, x):\n        return F.relu(self.bn(self.conv(x)))\n\nclass EncoderBlock(nn.Module):\n    \"\"\"编码器块：两个卷积层 + 最大池化\"\"\"\n    def __init__(self, in_channels, out_channels):\n        super(EncoderBlock, self).__init__()\n        self.conv1 = ConvBlock(in_channels, out_channels)\n        self.conv2 = ConvBlock(out_channels, out_channels)\n        self.pool = nn.MaxPool2d(2)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        pool = self.pool(x)\n        return pool, x  # 返回池化后的结果和特征，后者用于跳跃连接\n\nclass DecoderBlock(nn.Module):\n    \"\"\"解码器块：上采样 + 两个卷积层\"\"\"\n    def __init__(self, in_channels, out_channels):\n        super(DecoderBlock, self).__init__()\n        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n        self.conv1 = ConvBlock(in_channels, out_channels)  # 输入通道数为in_channels，因为要与跳跃连接拼接\n        self.conv2 = ConvBlock(out_channels, out_channels)\n        \n    def forward(self, x, skip):\n        x = self.up(x)\n        \n        # 确保尺寸匹配\n        diff_h = skip.size()[2] - x.size()[2]\n        diff_w = skip.size()[3] - x.size()[3]\n        \n        x = F.pad(x, [diff_w // 2, diff_w - diff_w // 2, diff_h // 2, diff_h - diff_h // 2])\n        \n        # 拼接跳跃连接的特征\n        x = torch.cat([skip, x], dim=1)\n        \n        x = self.conv1(x)\n        x = self.conv2(x)\n        return x\n\nclass ImprovedChangeDetectionModel(nn.Module):\n    \"\"\"改进的变化检测模型：使用UNet架构，加入跳跃连接和注意力机制\"\"\"\n    def __init__(self, in_channels=100, out_channels=1):\n        super(ImprovedChangeDetectionModel, self).__init__()\n        \n        # 共享编码器\n        self.encoder1 = EncoderBlock(in_channels, 64)\n        self.encoder2 = EncoderBlock(64, 128)\n        self.encoder3 = EncoderBlock(128, 256)\n        \n        # 差异特征编码器\n        self.diff_encoder1 = EncoderBlock(in_channels, 64)\n        self.diff_encoder2 = EncoderBlock(64, 128)\n        self.diff_encoder3 = EncoderBlock(128, 256)\n        \n        # 瓶颈层\n        self.bottleneck = ConvBlock(256, 512)\n        \n        # 解码器层\n        self.decoder3 = DecoderBlock(512, 256)\n        self.decoder2 = DecoderBlock(256, 128)\n        self.decoder1 = DecoderBlock(128, 64)\n        \n        # 输出层\n        self.output_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n        \n    def forward(self, x1, x2):\n        # 计算差值图像\n        x_diff = torch.abs(x1 - x2)\n        \n        # 处理第一时相图像\n        pool1_1, skip1_1 = self.encoder1(x1)\n        pool1_2, skip1_2 = self.encoder2(pool1_1)\n        pool1_3, skip1_3 = self.encoder3(pool1_2)\n        \n        # 处理差值图像\n        pool_d1, skip_d1 = self.diff_encoder1(x_diff)\n        pool_d2, skip_d2 = self.diff_encoder2(pool_d1)\n        pool_d3, skip_d3 = self.diff_encoder3(pool_d2)\n        \n        # 融合特征\n        bottle = self.bottleneck(pool1_3 + pool_d3)\n        \n        # 解码过程，使用跳跃连接\n        up3 = self.decoder3(bottle, skip1_3 + skip_d3)\n        up2 = self.decoder2(up3, skip1_2 + skip_d2)\n        up1 = self.decoder1(up2, skip1_1 + skip_d1)\n        \n        # 输出变化概率图\n        output = self.output_conv(up1)\n        return torch.sigmoid(output)\n\n# 实例化改进的模型\nmodel = ImprovedChangeDetectionModel(in_channels=len(selected_bands))\n\n\n# ============== 改进的训练设置 ==============\n\n# 使用加权BCE损失处理类别不平衡问题\ndef weighted_bce_loss(outputs, targets, weight_pos=2.0):\n    \"\"\"\n    加权二元交叉熵损失，给正样本（变化区域）更高的权重\n    \"\"\"\n    loss = F.binary_cross_entropy(outputs, targets, reduction='none')\n    \n    # 计算正样本权重\n    weights = torch.ones_like(targets)\n    weights[targets > 0.5] = weight_pos\n    \n    # 应用权重\n    weighted_loss = weights * loss\n    return weighted_loss.mean()\n\n# 定义损失函数和优化器\ncriterion = weighted_bce_loss\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # 添加权重衰减防止过拟合\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n\n# ============== 训练和验证函数 ==============\n\ndef train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=50, patience=10):\n    \"\"\"训练函数，包含早停机制和模型保存\"\"\"\n    best_val_loss = float('inf')\n    patience_counter = 0\n    best_model_path = save_path / 'best_model.pth'\n    history = {\n        'train_loss': [], 'val_loss': [], \n        'train_accuracy': [], 'val_accuracy': [],\n        'train_precision': [], 'val_precision': [],\n        'train_recall': [], 'val_recall': [],\n        'train_f1': [], 'val_f1': [],\n        'learning_rate': []\n    }\n    \n    for epoch in range(epochs):\n        # 训练阶段\n        model.train()\n        train_loss = 0.0\n        train_preds = []\n        train_labels = []\n        \n        for x1, x2, y in train_loader:\n            optimizer.zero_grad()\n            outputs = model(x1, x2)\n            \n            # 使用自定义加权损失\n            loss = criterion(outputs, y)\n            \n            loss.backward()\n            \n            # 梯度裁剪，防止梯度爆炸\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            \n            optimizer.step()\n            train_loss += loss.item()\n            \n            # 收集训练预测结果\n            preds = (outputs > 0.5).float()\n            train_preds.extend(preds.cpu().numpy().flatten())\n            train_labels.extend(y.cpu().numpy().flatten())\n        \n        train_loss /= len(train_loader)\n        \n        # 计算训练指标\n        train_accuracy = accuracy_score(train_labels, train_preds)\n        train_precision = precision_score(train_labels, train_preds)\n        train_recall = recall_score(train_labels, train_preds)\n        train_f1 = f1_score(train_labels, train_preds)\n        \n        # 验证阶段\n        model.eval()\n        val_loss = 0.0\n        val_preds = []\n        val_labels = []\n        \n        with torch.no_grad():\n            for x1, x2, y in val_loader:\n                outputs = model(x1, x2)\n                loss = criterion(outputs, y)\n                val_loss += loss.item()\n                \n                # 收集验证预测结果\n                preds = (outputs > 0.5).float()\n                val_preds.extend(preds.cpu().numpy().flatten())\n                val_labels.extend(y.cpu().numpy().flatten())\n                \n        val_loss /= len(val_loader)\n        \n        # 计算验证指标\n        val_accuracy = accuracy_score(val_labels, val_preds)\n        val_precision = precision_score(val_labels, val_preds)\n        val_recall = recall_score(val_labels, val_preds)\n        val_f1 = f1_score(val_labels, val_preds)\n        \n        # 更新学习率\n        scheduler.step(val_loss)\n        current_lr = optimizer.param_groups[0]['lr']\n        \n        # 记录历史\n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['train_accuracy'].append(train_accuracy)\n        history['val_accuracy'].append(val_accuracy)\n        history['train_precision'].append(train_precision)\n        history['val_precision'].append(val_precision)\n        history['train_recall'].append(train_recall)\n        history['val_recall'].append(val_recall)\n        history['train_f1'].append(train_f1)\n        history['val_f1'].append(val_f1)\n        history['learning_rate'].append(current_lr)\n        \n        # 打印训练状态\n        print(f'\\nEpoch {epoch+1}/{epochs}:')\n        print(f'Training - Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n        print(f'Validation - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}')\n        print(f'Learning Rate: {current_lr:.6f}')\n        \n        # 模型保存与早停\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), best_model_path)\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            \n        if patience_counter >= patience:\n            print(f'Early stopping triggered after {epoch+1} epochs')\n            break\n    \n    # 加载最佳模型\n    model.load_state_dict(torch.load(best_model_path))\n    \n    # 绘制训练历史\n    plt.figure(figsize=(15, 10))\n    \n    # 损失曲线\n    plt.subplot(2, 2, 1)\n    plt.plot(history['train_loss'], label='Training Loss')\n    plt.plot(history['val_loss'], label='Validation Loss')\n    plt.title('Loss History')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    # 准确率曲线\n    plt.subplot(2, 2, 2)\n    plt.plot(history['train_accuracy'], label='Training Accuracy')\n    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Accuracy History')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    # 精确率和召回率曲线\n    plt.subplot(2, 2, 3)\n    plt.plot(history['train_precision'], label='Training Precision')\n    plt.plot(history['val_precision'], label='Validation Precision')\n    plt.plot(history['train_recall'], label='Training Recall')\n    plt.plot(history['val_recall'], label='Validation Recall')\n    plt.title('Precision and Recall History')\n    plt.xlabel('Epoch')\n    plt.ylabel('Score')\n    plt.legend()\n    \n    # 学习率曲线\n    plt.subplot(2, 2, 4)\n    plt.plot(history['learning_rate'])\n    plt.title('Learning Rate')\n    plt.xlabel('Epoch')\n    plt.ylabel('LR')\n    \n    plt.tight_layout()\n    plt.savefig('training_history.png')\n    plt.show()\n    \n    return model\n\n# 训练模型\nprint(\"开始训练改进后的模型...\")\nmodel = train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=50, patience=15)\n\n# ============== 评估函数 ==============\n\ndef evaluate(model, test_loader):\n    \"\"\"\n    评估函数，计算各种性能指标并可视化混淆矩阵\n    \n    参数:\n        model: 待评估的模型\n        test_loader: 测试数据加载器\n        \n    返回:\n        包含各项评估指标的字典\n    \"\"\"\n    model.eval()  # 设置模型为评估模式\n    all_preds = []  # 存储所有预测结果\n    all_labels = []  # 存储所有真实标签\n    \n    # 收集所有预测和标签\n    with torch.no_grad():\n        for x1, x2, y in test_loader:\n            outputs = model(x1, x2)  # 前向传播\n            preds = (outputs > 0.5).float()  # 二值化预测结果，阈值为0.5\n            \n            # 将张量转换为一维数组并添加到列表\n            all_preds.extend(preds.cpu().numpy().flatten())\n            all_labels.extend(y.cpu().numpy().flatten())\n    \n    # 计算各种评估指标\n    accuracy = accuracy_score(all_labels, all_preds)  # 准确率\n    precision = precision_score(all_labels, all_preds)  # 精确率\n    recall = recall_score(all_labels, all_preds)  # 召回率\n    f1 = f1_score(all_labels, all_preds)  # F1分数\n    \n    # 绘制混淆矩阵\n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title('Confusion Matrix')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.show()\n    \n    # 返回包含所有指标的字典\n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1\n    }\n\n# 在测试集上评估改进后的模型\nprint(\"评估改进后的模型...\")\nmetrics = evaluate(model, test_loader)\nprint(\"\\n测试指标:\")\nprint(f\"Accuracy: {metrics['accuracy']:.4f}\")\nprint(f\"Precision: {metrics['precision']:.4f}\")\nprint(f\"Recall: {metrics['recall']:.4f}\")\nprint(f\"F1 Score: {metrics['f1']:.4f}\")\n\n# 改进的全图预测函数，使用重叠patch并平均结果\ndef predict_full_image_improved(model, before_data, after_data, patch_size=64, stride=32):\n    \"\"\"\n    改进的全图预测函数，使用重叠的patch并融合结果\n    \n    参数:\n        model: 训练好的模型\n        before_data: 变化前的图像数据，形状为(C,H,W)\n        after_data: 变化后的图像数据，形状为(C,H,W)\n        patch_size: 每个patch的大小\n        stride: 相邻patches的步长\n    \"\"\"\n    model.eval()\n    device = next(model.parameters()).device  # 获取模型所在设备\n    \n    # 获取原始图像尺寸\n    _, height, width = before_data.shape\n    \n    # 创建预测图和计数图（用于平均重叠区域）\n    pred_full = torch.zeros((height, width), device=device)\n    count = torch.zeros((height, width), device=device)\n    \n    # 使用重叠的patch进行预测\n    with torch.no_grad():\n        for i in range(0, height - patch_size + 1, stride):\n            for j in range(0, width - patch_size + 1, stride):\n                # 提取patch\n                before_patch = before_data[:, i:i+patch_size, j:j+patch_size].unsqueeze(0)\n                after_patch = after_data[:, i:i+patch_size, j:j+patch_size].unsqueeze(0)\n                \n                # 将patch移到模型所在设备\n                if before_patch.device != device:\n                    before_patch = before_patch.to(device)\n                    after_patch = after_patch.to(device)\n                \n                # 预测\n                pred_patch = model(before_patch, after_patch)\n                \n                # 将结果展平为2D张量 [64, 64]\n                pred_patch_flat = pred_patch.squeeze()\n                \n                # 累加到完整预测图中\n                pred_full[i:i+patch_size, j:j+patch_size] += pred_patch_flat\n                count[i:i+patch_size, j:j+patch_size] += 1\n    \n    # 平均重叠区域\n    count = torch.clamp(count, min=1)  # 避免除以零\n    pred_full = pred_full / count\n    \n    # 最后进行二值化\n    pred_binary = (pred_full > 0.5).float()\n    \n    # 添加通道维度以匹配期望的输出格式\n    pred_binary = pred_binary.unsqueeze(0)\n    \n    return pred_binary\n\n# 使用改进的全图预测函数\nprint(\"对全图进行变化检测预测...\")\npred_full = predict_full_image_improved(model, before_data, after_data)\nprint(\"预测完成，正在可视化结果...\")\n\n# 可视化全图对比结果\ndef visualize_full_image_comparison(before_data, after_data, gt_data, pred_full):\n    \"\"\"可视化全图对比结果\"\"\"\n    # 创建四子图布局\n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    \n    # 显示原始图像（使用第一个通道作为示例）\n    axes[0, 0].imshow(before_data[0].cpu().numpy(), cmap='gray')\n    axes[0, 0].set_title('Before Image (Channel 0)')\n    axes[0, 0].axis('off')\n    \n    axes[0, 1].imshow(after_data[0].cpu().numpy(), cmap='gray')\n    axes[0, 1].set_title('After Image (Channel 0)')\n    axes[0, 1].axis('off')\n    \n    # 显示真实标签和预测结果\n    axes[1, 0].imshow(gt_data.squeeze().cpu().numpy(), cmap='gray')\n    axes[1, 0].set_title('Ground Truth')\n    axes[1, 0].axis('off')\n    \n    axes[1, 1].imshow(pred_full.squeeze().cpu().numpy(), cmap='gray')\n    axes[1, 1].set_title('Prediction')\n    axes[1, 1].axis('off')\n    \n    plt.tight_layout()\n    plt.savefig('improved_full_image_comparison.png', dpi=300)\n    plt.show()\n\n# 显示全图对比\nvisualize_full_image_comparison(before_data, after_data, gt_data, pred_full)\n\n# 计算全图的评估指标\npred_binary = pred_full.cpu().numpy().flatten()\ngt_binary = gt_data.cpu().numpy().flatten()\n\naccuracy = accuracy_score(gt_binary, pred_binary)\nprecision = precision_score(gt_binary, pred_binary)\nrecall = recall_score(gt_binary, pred_binary)\nf1 = f1_score(gt_binary, pred_binary)\n\nprint(\"\\n改进后的全图评估指标:\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n\n# 示例测试区域的可视化\ndef visualize_predictions(model, test_dataset, num_samples=4):\n    \"\"\"可视化模型预测结果\"\"\"\n    model.eval()\n    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n    \n    for i in range(num_samples):\n        x1, x2, y = test_dataset[i]\n        \n        with torch.no_grad():\n            pred = model(x1.unsqueeze(0), x2.unsqueeze(0))\n            pred = (pred > 0.5).float()\n        \n        axes[i, 0].imshow(x1[0].cpu().numpy(), cmap='gray')\n        axes[i, 0].set_title('Before')\n        axes[i, 0].axis('off')\n        \n        axes[i, 1].imshow(y.squeeze().cpu().numpy(), cmap='gray')\n        axes[i, 1].set_title('Ground Truth')\n        axes[i, 1].axis('off')\n        \n        axes[i, 2].imshow(pred.squeeze().cpu().numpy(), cmap='gray')\n        axes[i, 2].set_title('Prediction')\n        axes[i, 2].axis('off')\n    \n    plt.tight_layout()\n    plt.savefig('improved_prediction_samples.png', dpi=300)\n    plt.show()\n\n# 显示测试样本的预测结果\nvisualize_predictions(model, test_dataset)","outputs":[{"output_type":"stream","name":"stdout","text":"Before Data Range: -142.0 to 7960.0\nAfter Data Range: -227.0 to 7938.0\nGround Truth Unique Values: tensor([  0., 255.])\n数据形状 - Before: torch.Size([100, 463, 241]), After: torch.Size([100, 463, 241]), GT: torch.Size([1, 463, 241])\n提取的patch数量: 78\nPatch形状 - Before: torch.Size([78, 100, 64, 64]), GT: torch.Size([78, 1, 64, 64])\n开始训练改进后的模型...\n\nEpoch 1/50:\nTraining - Loss: 0.6438, Accuracy: 0.7237, Precision: 0.2643, Recall: 0.9592, F1: 0.4145\nValidation - Loss: 0.7356, Accuracy: 0.5848, Precision: 0.2240, Recall: 0.9943, F1: 0.3656\nLearning Rate: 0.001000\n\nEpoch 2/50:\nTraining - Loss: 0.4053, Accuracy: 0.9522, Precision: 0.7114, Recall: 0.8939, F1: 0.7922\nValidation - Loss: 0.5417, Accuracy: 0.9418, Precision: 0.7112, Recall: 0.8693, F1: 0.7824\nLearning Rate: 0.001000\n\nEpoch 3/50:\nTraining - Loss: 0.3709, Accuracy: 0.9512, Precision: 0.7052, Recall: 0.8962, F1: 0.7893\nValidation - Loss: 0.4684, Accuracy: 0.9042, Precision: 0.5733, Recall: 0.7964, F1: 0.6667\nLearning Rate: 0.001000\n\nEpoch 4/50:\nTraining - Loss: 0.3328, Accuracy: 0.9506, Precision: 0.6982, Recall: 0.9080, F1: 0.7894\nValidation - Loss: 0.3994, Accuracy: 0.9482, Precision: 0.9803, Recall: 0.5814, F1: 0.7299\nLearning Rate: 0.001000\n\nEpoch 5/50:\nTraining - Loss: 0.2974, Accuracy: 0.9637, Precision: 0.7956, Recall: 0.8661, F1: 0.8293\nValidation - Loss: 0.3187, Accuracy: 0.9615, Precision: 0.9279, Recall: 0.7378, F1: 0.8220\nLearning Rate: 0.001000\n\nEpoch 6/50:\nTraining - Loss: 0.2670, Accuracy: 0.9581, Precision: 0.7301, Recall: 0.9347, F1: 0.8198\nValidation - Loss: 0.2986, Accuracy: 0.9695, Precision: 0.9493, Recall: 0.7890, F1: 0.8618\nLearning Rate: 0.001000\n\nEpoch 7/50:\nTraining - Loss: 0.2477, Accuracy: 0.9620, Precision: 0.7634, Recall: 0.9085, F1: 0.8296\nValidation - Loss: 0.2524, Accuracy: 0.9711, Precision: 0.9242, Recall: 0.8281, F1: 0.8735\nLearning Rate: 0.001000\n\nEpoch 8/50:\nTraining - Loss: 0.2160, Accuracy: 0.9729, Precision: 0.8415, Recall: 0.9048, F1: 0.8720\nValidation - Loss: 0.2496, Accuracy: 0.9726, Precision: 0.8610, Recall: 0.9207, F1: 0.8899\nLearning Rate: 0.001000\n\nEpoch 9/50:\nTraining - Loss: 0.2236, Accuracy: 0.9591, Precision: 0.7386, Recall: 0.9274, F1: 0.8223\nValidation - Loss: 0.2330, Accuracy: 0.9699, Precision: 0.9238, Recall: 0.8172, F1: 0.8672\nLearning Rate: 0.001000\n\nEpoch 10/50:\nTraining - Loss: 0.2044, Accuracy: 0.9707, Precision: 0.8628, Recall: 0.8475, F1: 0.8551\nValidation - Loss: 0.2429, Accuracy: 0.9613, Precision: 0.7841, Recall: 0.9368, F1: 0.8536\nLearning Rate: 0.001000\n\nEpoch 11/50:\nTraining - Loss: 0.2107, Accuracy: 0.9612, Precision: 0.7613, Recall: 0.9029, F1: 0.8260\nValidation - Loss: 0.1900, Accuracy: 0.9634, Precision: 0.7885, Recall: 0.9515, F1: 0.8623\nLearning Rate: 0.001000\n\nEpoch 12/50:\nTraining - Loss: 0.1716, Accuracy: 0.9718, Precision: 0.8263, Recall: 0.9162, F1: 0.8689\nValidation - Loss: 0.1693, Accuracy: 0.9740, Precision: 0.9528, Recall: 0.8250, F1: 0.8843\nLearning Rate: 0.001000\n\nEpoch 13/50:\nTraining - Loss: 0.1726, Accuracy: 0.9720, Precision: 0.8539, Recall: 0.8754, F1: 0.8645\nValidation - Loss: 0.1861, Accuracy: 0.9687, Precision: 0.8174, Recall: 0.9525, F1: 0.8798\nLearning Rate: 0.001000\n\nEpoch 14/50:\nTraining - Loss: 0.1626, Accuracy: 0.9671, Precision: 0.7835, Recall: 0.9365, F1: 0.8532\nValidation - Loss: 0.1863, Accuracy: 0.9739, Precision: 0.8629, Recall: 0.9309, F1: 0.8956\nLearning Rate: 0.001000\n\nEpoch 15/50:\nTraining - Loss: 0.1535, Accuracy: 0.9725, Precision: 0.8395, Recall: 0.9022, F1: 0.8697\nValidation - Loss: 0.1600, Accuracy: 0.9765, Precision: 0.9142, Recall: 0.8877, F1: 0.9008\nLearning Rate: 0.001000\n\nEpoch 16/50:\nTraining - Loss: 0.1693, Accuracy: 0.9661, Precision: 0.8049, Recall: 0.8814, F1: 0.8414\nValidation - Loss: 0.1564, Accuracy: 0.9774, Precision: 0.8865, Recall: 0.9310, F1: 0.9082\nLearning Rate: 0.001000\n\nEpoch 17/50:\nTraining - Loss: 0.1397, Accuracy: 0.9738, Precision: 0.8393, Recall: 0.9194, F1: 0.8775\nValidation - Loss: 0.1415, Accuracy: 0.9654, Precision: 0.7958, Recall: 0.9587, F1: 0.8697\nLearning Rate: 0.001000\n\nEpoch 18/50:\nTraining - Loss: 0.1363, Accuracy: 0.9722, Precision: 0.8259, Recall: 0.9214, F1: 0.8711\nValidation - Loss: 0.1502, Accuracy: 0.9719, Precision: 0.8382, Recall: 0.9500, F1: 0.8906\nLearning Rate: 0.001000\n\nEpoch 19/50:\nTraining - Loss: 0.1294, Accuracy: 0.9745, Precision: 0.8455, Recall: 0.9181, F1: 0.8803\nValidation - Loss: 0.1345, Accuracy: 0.9746, Precision: 0.8525, Recall: 0.9544, F1: 0.9005\nLearning Rate: 0.001000\n\nEpoch 20/50:\nTraining - Loss: 0.1225, Accuracy: 0.9733, Precision: 0.8277, Recall: 0.9328, F1: 0.8771\nValidation - Loss: 0.1561, Accuracy: 0.9719, Precision: 0.9642, Recall: 0.7959, F1: 0.8720\nLearning Rate: 0.001000\n\nEpoch 21/50:\nTraining - Loss: 0.1165, Accuracy: 0.9769, Precision: 0.8614, Recall: 0.9213, F1: 0.8904\nValidation - Loss: 0.1243, Accuracy: 0.9705, Precision: 0.8283, Recall: 0.9520, F1: 0.8859\nLearning Rate: 0.001000\n\nEpoch 22/50:\nTraining - Loss: 0.1194, Accuracy: 0.9741, Precision: 0.8462, Recall: 0.9119, F1: 0.8778\nValidation - Loss: 0.1279, Accuracy: 0.9774, Precision: 0.9544, Recall: 0.8533, F1: 0.9010\nLearning Rate: 0.001000\n\nEpoch 23/50:\nTraining - Loss: 0.1211, Accuracy: 0.9757, Precision: 0.8760, Recall: 0.8877, F1: 0.8818\nValidation - Loss: 0.1124, Accuracy: 0.9744, Precision: 0.8573, Recall: 0.9447, F1: 0.8989\nLearning Rate: 0.001000\n\nEpoch 24/50:\nTraining - Loss: 0.1132, Accuracy: 0.9710, Precision: 0.8006, Recall: 0.9525, F1: 0.8700\nValidation - Loss: 0.1217, Accuracy: 0.9727, Precision: 0.8536, Recall: 0.9336, F1: 0.8918\nLearning Rate: 0.001000\n\nEpoch 25/50:\nTraining - Loss: 0.1034, Accuracy: 0.9772, Precision: 0.8647, Recall: 0.9199, F1: 0.8914\nValidation - Loss: 0.1089, Accuracy: 0.9736, Precision: 0.8505, Recall: 0.9467, F1: 0.8961\nLearning Rate: 0.001000\n\nEpoch 26/50:\nTraining - Loss: 0.1130, Accuracy: 0.9746, Precision: 0.8634, Recall: 0.8916, F1: 0.8773\nValidation - Loss: 0.1582, Accuracy: 0.9601, Precision: 0.7586, Recall: 0.9804, F1: 0.8554\nLearning Rate: 0.001000\n\nEpoch 27/50:\nTraining - Loss: 0.0985, Accuracy: 0.9750, Precision: 0.8273, Recall: 0.9540, F1: 0.8862\nValidation - Loss: 0.1113, Accuracy: 0.9816, Precision: 0.9443, Recall: 0.8999, F1: 0.9216\nLearning Rate: 0.001000\n\nEpoch 28/50:\nTraining - Loss: 0.0937, Accuracy: 0.9801, Precision: 0.8867, Recall: 0.9230, F1: 0.9045\nValidation - Loss: 0.0977, Accuracy: 0.9800, Precision: 0.9091, Recall: 0.9265, F1: 0.9177\nLearning Rate: 0.001000\n\nEpoch 29/50:\nTraining - Loss: 0.0923, Accuracy: 0.9784, Precision: 0.8661, Recall: 0.9328, F1: 0.8982\nValidation - Loss: 0.0962, Accuracy: 0.9757, Precision: 0.8563, Recall: 0.9587, F1: 0.9046\nLearning Rate: 0.001000\n\nEpoch 30/50:\nTraining - Loss: 0.0938, Accuracy: 0.9790, Precision: 0.8825, Recall: 0.9161, F1: 0.8990\nValidation - Loss: 0.0948, Accuracy: 0.9829, Precision: 0.9316, Recall: 0.9258, F1: 0.9287\nLearning Rate: 0.001000\n\nEpoch 31/50:\nTraining - Loss: 0.0881, Accuracy: 0.9781, Precision: 0.8518, Recall: 0.9503, F1: 0.8984\nValidation - Loss: 0.1092, Accuracy: 0.9795, Precision: 0.9689, Recall: 0.8571, F1: 0.9096\nLearning Rate: 0.001000\n\nEpoch 32/50:\nTraining - Loss: 0.0902, Accuracy: 0.9790, Precision: 0.8700, Recall: 0.9332, F1: 0.9005\nValidation - Loss: 0.1001, Accuracy: 0.9706, Precision: 0.8145, Recall: 0.9784, F1: 0.8889\nLearning Rate: 0.001000\n\nEpoch 33/50:\nTraining - Loss: 0.0791, Accuracy: 0.9820, Precision: 0.8841, Recall: 0.9479, F1: 0.9149\nValidation - Loss: 0.0991, Accuracy: 0.9821, Precision: 0.9665, Recall: 0.8818, F1: 0.9222\nLearning Rate: 0.001000\n\nEpoch 34/50:\nTraining - Loss: 0.0938, Accuracy: 0.9771, Precision: 0.8641, Recall: 0.9197, F1: 0.8911\nValidation - Loss: 0.0815, Accuracy: 0.9809, Precision: 0.8918, Recall: 0.9577, F1: 0.9236\nLearning Rate: 0.001000\n\nEpoch 35/50:\nTraining - Loss: 0.0791, Accuracy: 0.9813, Precision: 0.8882, Recall: 0.9336, F1: 0.9103\nValidation - Loss: 0.0876, Accuracy: 0.9820, Precision: 0.9475, Recall: 0.9006, F1: 0.9235\nLearning Rate: 0.001000\n\nEpoch 36/50:\nTraining - Loss: 0.0774, Accuracy: 0.9828, Precision: 0.9060, Recall: 0.9274, F1: 0.9166\nValidation - Loss: 0.0812, Accuracy: 0.9785, Precision: 0.8697, Recall: 0.9657, F1: 0.9152\nLearning Rate: 0.001000\n\nEpoch 37/50:\nTraining - Loss: 0.0770, Accuracy: 0.9799, Precision: 0.8578, Recall: 0.9619, F1: 0.9069\nValidation - Loss: 0.0741, Accuracy: 0.9854, Precision: 0.9456, Recall: 0.9324, F1: 0.9390\nLearning Rate: 0.001000\n\nEpoch 38/50:\nTraining - Loss: 0.0740, Accuracy: 0.9831, Precision: 0.9037, Recall: 0.9334, F1: 0.9183\nValidation - Loss: 0.0852, Accuracy: 0.9787, Precision: 0.8818, Recall: 0.9508, F1: 0.9150\nLearning Rate: 0.001000\n\nEpoch 39/50:\nTraining - Loss: 0.0694, Accuracy: 0.9822, Precision: 0.8770, Recall: 0.9596, F1: 0.9164\nValidation - Loss: 0.0780, Accuracy: 0.9828, Precision: 0.9233, Recall: 0.9347, F1: 0.9290\nLearning Rate: 0.001000\n\nEpoch 40/50:\nTraining - Loss: 0.0755, Accuracy: 0.9834, Precision: 0.9131, Recall: 0.9256, F1: 0.9193\nValidation - Loss: 0.0849, Accuracy: 0.9753, Precision: 0.8430, Recall: 0.9767, F1: 0.9049\nLearning Rate: 0.001000\n\nEpoch 41/50:\nTraining - Loss: 0.0784, Accuracy: 0.9773, Precision: 0.8388, Recall: 0.9624, F1: 0.8964\nValidation - Loss: 0.0824, Accuracy: 0.9817, Precision: 0.9261, Recall: 0.9217, F1: 0.9239\nLearning Rate: 0.001000\n\nEpoch 42/50:\nTraining - Loss: 0.0770, Accuracy: 0.9825, Precision: 0.9124, Recall: 0.9166, F1: 0.9145\nValidation - Loss: 0.0751, Accuracy: 0.9845, Precision: 0.9372, Recall: 0.9341, F1: 0.9356\nLearning Rate: 0.001000\n\nEpoch 43/50:\nTraining - Loss: 0.0769, Accuracy: 0.9788, Precision: 0.8621, Recall: 0.9431, F1: 0.9007\nValidation - Loss: 0.0710, Accuracy: 0.9832, Precision: 0.9111, Recall: 0.9532, F1: 0.9317\nLearning Rate: 0.001000\n\nEpoch 44/50:\nTraining - Loss: 0.0677, Accuracy: 0.9809, Precision: 0.8626, Recall: 0.9666, F1: 0.9117\nValidation - Loss: 0.0694, Accuracy: 0.9818, Precision: 0.8928, Recall: 0.9643, F1: 0.9272\nLearning Rate: 0.001000\n\nEpoch 45/50:\nTraining - Loss: 0.0684, Accuracy: 0.9850, Precision: 0.9237, Recall: 0.9294, F1: 0.9265\nValidation - Loss: 0.0854, Accuracy: 0.9711, Precision: 0.8160, Recall: 0.9807, F1: 0.8908\nLearning Rate: 0.001000\n\nEpoch 46/50:\nTraining - Loss: 0.0666, Accuracy: 0.9822, Precision: 0.8772, Recall: 0.9598, F1: 0.9167\nValidation - Loss: 0.0720, Accuracy: 0.9861, Precision: 0.9614, Recall: 0.9219, F1: 0.9412\nLearning Rate: 0.001000\n\nEpoch 47/50:\nTraining - Loss: 0.0626, Accuracy: 0.9849, Precision: 0.9033, Recall: 0.9540, F1: 0.9279\nValidation - Loss: 0.0691, Accuracy: 0.9858, Precision: 0.9377, Recall: 0.9444, F1: 0.9410\nLearning Rate: 0.001000\n\nEpoch 48/50:\nTraining - Loss: 0.0572, Accuracy: 0.9862, Precision: 0.9096, Recall: 0.9600, F1: 0.9341\nValidation - Loss: 0.0705, Accuracy: 0.9839, Precision: 0.9351, Recall: 0.9309, F1: 0.9330\nLearning Rate: 0.001000\n\nEpoch 49/50:\nTraining - Loss: 0.0577, Accuracy: 0.9852, Precision: 0.8996, Recall: 0.9623, F1: 0.9299\nValidation - Loss: 0.0679, Accuracy: 0.9865, Precision: 0.9641, Recall: 0.9219, F1: 0.9425\nLearning Rate: 0.001000\n\nEpoch 50/50:\nTraining - Loss: 0.0689, Accuracy: 0.9823, Precision: 0.8990, Recall: 0.9315, F1: 0.9150\nValidation - Loss: 0.0763, Accuracy: 0.9778, Precision: 0.8601, Recall: 0.9740, F1: 0.9135\nLearning Rate: 0.001000\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x1000 with 4 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/4C066F2863894600ADC78C2DDEC87224/stob1nkvmo.png\">"},"metadata":{}},{"output_type":"stream","name":"stdout","text":"评估改进后的模型...\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/4C066F2863894600ADC78C2DDEC87224/stob1nwb5f.png\">"},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n测试指标:\nAccuracy: 0.9833\nPrecision: 0.9035\nRecall: 0.8803\nF1 Score: 0.8918\n对全图进行变化检测预测...\n预测完成，正在可视化结果...\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x1200 with 4 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/4C066F2863894600ADC78C2DDEC87224/stob1t250s.png\">"},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n改进后的全图评估指标:\nAccuracy: 0.9861\nPrecision: 0.9426\nRecall: 0.8948\nF1 Score: 0.9181\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x2000 with 12 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/4C066F2863894600ADC78C2DDEC87224/stob1v9r0a.png\">"},"metadata":{}}],"execution_count":11}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}